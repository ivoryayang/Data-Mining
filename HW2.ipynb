{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2. Text Modeling\n",
    "\n",
    "In this assignment, we ask you to create a classifier for detecting spam. Please populate this Jupyter notebook with your code and embedded results (outputs, figures, etc) and submit it on Canvas as a zip file.  <B\n",
    "\n",
    "Useful libraries for this assignment: <br>\n",
    "(1) sklearn\n",
    "(2) nltk\n",
    "(3) gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (76 points)\n",
    "You have been provided a spam dataset (SPAM.csv). Each line in the dataset corresponds to one message and has a label of either \"ham\" or \"spam\". In this assignment, you are experimenting with different features and models to create the best spam detector possible.  \n",
    "\n",
    "Load the data into a dataframe. Divide the data into a random train/test set with the ratio 85/15. Finally, use sklearn to run the following experiments.\n",
    "\n",
    "**(A)[10 points]** Train and evaluate the following models:\n",
    "\n",
    "(1) Logistic Regression (LR)\n",
    "<br>\n",
    "(2) Random Forest (RF)\n",
    "<br>\n",
    "\n",
    "\n",
    "**(B)[24 points]** and the combination of all following preprocessing (total of 8 combinations):\n",
    "<br>\n",
    "(1) with and without lowercasing <br> (2) with and without stopword removal (3) with and without lemmatization <br>\n",
    "\n",
    "**(C)[24 points]** and the following lexical features (total of 6 combinations): \n",
    "<br>\n",
    "(1) unigrams <br>(2) unigrams and bigrams <br>(3) unigrams, bigrams and trigrams <br>\n",
    "(4) tfidf unigrams <br>(5) tfidf  unigrams and bigrams <br>(6) tfidf unigrams, bigrams and trigrams  <br>\n",
    "\n",
    "So that's 2 model types x 8 possible prepreocessing x 6 possible features = 96 models <br>\n",
    "\n",
    "**(D)[10 points]** Create a dataframe where each row is one of the models and 15 columns. The first 9 columns should be boolean and capture if the model used the following: <br>\n",
    "\n",
    "(1) lowercased: 1 / 0 <br>\n",
    "(2) stopwords_removed: 1 / 0 <br>\n",
    "(3) lemmatized: 1 / 0 <br>\n",
    "(4) unigrams : 1 / 0 <br>\n",
    "(5) bigrams :  1 / 0 <br>\n",
    "(6) trigrams :  1 / 0 <br>\n",
    "(7) tfidf unigrams :  1 / 0 <br>\n",
    "(8) tfidf bigrams :  1 / 0 <br>\n",
    "(9) tfidf trigrams :  1 / 0 <br>\n",
    "\n",
    "The last 6 columns should show the default f1 (default parameters), weighted f1, and accuracy of the models on the **train** and **test** sets: <br>\n",
    "\n",
    "(10) f1_train <br>\n",
    "(11) weighted_f1_train <br>\n",
    "(12) accuracy_train <br>\n",
    "(13) f1_test <br>\n",
    "(14) weighted_f1_test <br>\n",
    "(15) accuracy_test <br>\n",
    "\n",
    "**(E)[4 points]** <br>\n",
    "Which model has the best weighted f1 according to the train set? <br>\n",
    "Which model has the best weighted f1 according to the test set? <br>\n",
    "\n",
    "**(F)[4 points]** <br>\n",
    "Show the confusion matrix for the best-performing model on the test set. Explain what each element of the matrix means. <br>\n",
    "\n",
    "\n",
    "HINT 1: You should convert the \"spam\" category to 1 and the \"ham\" category to 0, sklearn models can only work with numbers. <br>\n",
    "\n",
    "HINT 2: You should make the whole thing systematically using good coding convetion instead of copy and pasting the models! I have created a partial skeleton template for Q1 below to guide you with this. You do NOT have to use this. This is just for your benefit. I have not included templates for the other questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ivoryang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ivoryang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message\n",
       "0            0  Go until jurong point, crazy.. Available only ...\n",
       "1            0                      Ok lar... Joking wif u oni...\n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3            0  U dun say so early hor... U c already then say...\n",
       "4            0  Nah I don't think he goes to usf, he lives aro...\n",
       "...        ...                                                ...\n",
       "5567         1  This is the 2nd time we have tried 2 contact u...\n",
       "5568         0               Will ü b going to esplanade fr home?\n",
       "5569         0  Pity, * was in mood for that. So...any other s...\n",
       "5570         0  The guy did some bitching but I acted like i'd...\n",
       "5571         0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# load data into dataframe\n",
    "data = pd.read_csv('SPAM.csv')\n",
    "\n",
    "# convert spam category to 1 and ham category to 0\n",
    "data['Category'] = data['Category'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into a random train/test set with the ratio 85/15\n",
    "X = data['Message']\n",
    "y = data['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokenized_text,lowercase=False, remove_stopwords=False,lemmatize=False):\n",
    "    \n",
    "    # initialize an empty list to store the preprocessed text\n",
    "    cleaned_tokenized_text = []\n",
    "    \n",
    "    for token in tokenized_text:\n",
    "        # lowercase\n",
    "        if lowercase:\n",
    "            token = token.lower()\n",
    "            \n",
    "        # remove stopwords\n",
    "        if remove_stopwords:\n",
    "            if token not in stopwords.words('english'):\n",
    "                cleaned_tokenized_text.append(token)\n",
    "        else:\n",
    "            cleaned_tokenized_text.append(token)\n",
    "        \n",
    "        # lemmatize\n",
    "        if lemmatize:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            token = lemmatizer.lemmatize(token)\n",
    "\n",
    "        \n",
    "    return cleaned_tokenized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(cleaned_tokenized_text_train, cleaned_tokenized_text_test, tfidf_option, ngram_range):\n",
    "    \n",
    "    if tfidf_option:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, lowercase=False)\n",
    "        \n",
    "    else:\n",
    "        vectorizer = CountVectorizer(ngram_range=ngram_range, lowercase=False)\n",
    "\n",
    "    # Transform the list of tokenized words directly\n",
    "    features_train = vectorizer.fit_transform(cleaned_tokenized_text_train)\n",
    "    features_test = vectorizer.transform(cleaned_tokenized_text_test)\n",
    "    \n",
    "    return features_train, features_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type,train_features, train_labels):\n",
    "    \n",
    "    if model_type == \"LogisticRegression\":\n",
    "        trained_model = LogisticRegression(random_state=27)\n",
    "        \n",
    "    elif model_type == \"RandomForest\":\n",
    "        trained_model = RandomForestClassifier(random_state=27)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    trained_model.fit(train_features, train_labels)\n",
    "    \n",
    "    return trained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trained_model,metric,eval_features,eval_labels):\n",
    "    \n",
    "    if metric == \"accuracy\":\n",
    "        predictions = trained_model.predict(eval_features)\n",
    "        model_eval = accuracy_score(eval_labels, predictions)\n",
    "        \n",
    "    elif metric == \"weighted_f1\":\n",
    "        predictions = trained_model.predict(eval_features)\n",
    "        model_eval = f1_score(eval_labels, predictions, average='weighted')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported evaluation metric\")\n",
    "\n",
    "    return model_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    results = []\n",
    "    preprocessing_options = [False, True]\n",
    "    model_option = ['LogisticRegression', 'RandomForest']\n",
    "    ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "    \n",
    "    for model_type in model_option:\n",
    "        for lowercase in preprocessing_options:\n",
    "            for remove_stopwords in preprocessing_options:\n",
    "                for lemmatize in preprocessing_options:\n",
    "                    for ngram_range in ngram_ranges:\n",
    "                        for tfidf_option in preprocessing_options:\n",
    "                            cleaned_train_data = X_train.apply(lambda x: ' '.join(preprocess(word_tokenize(x), lowercase, remove_stopwords, lemmatize)))\n",
    "                            cleaned_test_data = X_test.apply(\n",
    "                                lambda x: ' '.join(preprocess(word_tokenize(x), lowercase, remove_stopwords, lemmatize))\n",
    "                            )\n",
    "                            train_features, test_features = extract_features(cleaned_train_data, cleaned_test_data, tfidf_option, ngram_range)\n",
    "                            model = train_model(model_type, train_features, y_train)\n",
    "                            f1_train = evaluate_model(model, 'weighted_f1', train_features, y_train)\n",
    "                            f1_test = evaluate_model(model, 'weighted_f1', test_features, y_test)\n",
    "                            result_row = {\n",
    "                                'model_type': model_type,\n",
    "                                'lowercased': lowercase,\n",
    "                                'stopwords_removed': remove_stopwords,\n",
    "                                'lemmatized': lemmatize,\n",
    "                                'unigrams': ngram_range == (1, 1),\n",
    "                                'bigrams': ngram_range == (1, 2),\n",
    "                                'trigrams': ngram_range == (1, 3),\n",
    "                                'tfidf_unigrams': tfidf_option,\n",
    "                                'tfidf_bigrams': tfidf_option,\n",
    "                                'tfidf_trigrams': tfidf_option,\n",
    "                                'f1_train': f1_train,\n",
    "                                'weighted_f1_train': f1_train,  \n",
    "                                'accuracy_train': f1_train,\n",
    "                                'f1_test': f1_test,\n",
    "                                'weighted_f1_test': f1_test,    \n",
    "                                'accuracy_test': f1_test        \n",
    "                            }\n",
    "                            results.append(result_row)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            model_type  lowercased  stopwords_removed  lemmatized  unigrams  \\\n",
      "0   LogisticRegression       False              False       False      True   \n",
      "1   LogisticRegression       False              False       False      True   \n",
      "2   LogisticRegression       False              False       False     False   \n",
      "3   LogisticRegression       False              False       False     False   \n",
      "4   LogisticRegression       False              False       False     False   \n",
      "..                 ...         ...                ...         ...       ...   \n",
      "91        RandomForest        True               True        True      True   \n",
      "92        RandomForest        True               True        True     False   \n",
      "93        RandomForest        True               True        True     False   \n",
      "94        RandomForest        True               True        True     False   \n",
      "95        RandomForest        True               True        True     False   \n",
      "\n",
      "    bigrams  trigrams  tfidf_unigrams  tfidf_bigrams  tfidf_trigrams  \\\n",
      "0     False     False           False          False           False   \n",
      "1     False     False            True           True            True   \n",
      "2      True     False           False          False           False   \n",
      "3      True     False            True           True            True   \n",
      "4     False      True           False          False           False   \n",
      "..      ...       ...             ...            ...             ...   \n",
      "91    False     False            True           True            True   \n",
      "92     True     False           False          False           False   \n",
      "93     True     False            True           True            True   \n",
      "94    False      True           False          False           False   \n",
      "95    False      True            True           True            True   \n",
      "\n",
      "    f1_train  weighted_f1_train  accuracy_train   f1_test  weighted_f1_test  \\\n",
      "0   0.997881           0.997881        0.997881  0.977923          0.977923   \n",
      "1   0.968533           0.968533        0.968533  0.948729          0.948729   \n",
      "2   0.999366           0.999366        0.999366  0.975388          0.975388   \n",
      "3   0.951599           0.951599        0.951599  0.930159          0.930159   \n",
      "4   0.999366           0.999366        0.999366  0.972834          0.972834   \n",
      "..       ...                ...             ...       ...               ...   \n",
      "91  1.000000           1.000000        1.000000  0.962286          0.962286   \n",
      "92  1.000000           1.000000        1.000000  0.959620          0.959620   \n",
      "93  1.000000           1.000000        1.000000  0.959620          0.959620   \n",
      "94  1.000000           1.000000        1.000000  0.951487          0.951487   \n",
      "95  1.000000           1.000000        1.000000  0.954222          0.954222   \n",
      "\n",
      "    accuracy_test  \n",
      "0        0.977923  \n",
      "1        0.948729  \n",
      "2        0.975388  \n",
      "3        0.930159  \n",
      "4        0.972834  \n",
      "..            ...  \n",
      "91       0.962286  \n",
      "92       0.959620  \n",
      "93       0.959620  \n",
      "94       0.951487  \n",
      "95       0.954222  \n",
      "\n",
      "[96 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "results_df = run_experiments()\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>lowercased</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>tfidf_unigrams</th>\n",
       "      <th>tfidf_bigrams</th>\n",
       "      <th>tfidf_trigrams</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>weighted_f1_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>0.977923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.968533</td>\n",
       "      <td>0.968533</td>\n",
       "      <td>0.968533</td>\n",
       "      <td>0.948729</td>\n",
       "      <td>0.948729</td>\n",
       "      <td>0.948729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.975388</td>\n",
       "      <td>0.975388</td>\n",
       "      <td>0.975388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.951599</td>\n",
       "      <td>0.951599</td>\n",
       "      <td>0.951599</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.930159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.972834</td>\n",
       "      <td>0.972834</td>\n",
       "      <td>0.972834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.962286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959620</td>\n",
       "      <td>0.959620</td>\n",
       "      <td>0.959620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959620</td>\n",
       "      <td>0.959620</td>\n",
       "      <td>0.959620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951487</td>\n",
       "      <td>0.951487</td>\n",
       "      <td>0.951487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954222</td>\n",
       "      <td>0.954222</td>\n",
       "      <td>0.954222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_type  lowercased  stopwords_removed  lemmatized  unigrams  \\\n",
       "0   LogisticRegression       False              False       False      True   \n",
       "1   LogisticRegression       False              False       False      True   \n",
       "2   LogisticRegression       False              False       False     False   \n",
       "3   LogisticRegression       False              False       False     False   \n",
       "4   LogisticRegression       False              False       False     False   \n",
       "..                 ...         ...                ...         ...       ...   \n",
       "91        RandomForest        True               True        True      True   \n",
       "92        RandomForest        True               True        True     False   \n",
       "93        RandomForest        True               True        True     False   \n",
       "94        RandomForest        True               True        True     False   \n",
       "95        RandomForest        True               True        True     False   \n",
       "\n",
       "    bigrams  trigrams  tfidf_unigrams  tfidf_bigrams  tfidf_trigrams  \\\n",
       "0     False     False           False          False           False   \n",
       "1     False     False            True           True            True   \n",
       "2      True     False           False          False           False   \n",
       "3      True     False            True           True            True   \n",
       "4     False      True           False          False           False   \n",
       "..      ...       ...             ...            ...             ...   \n",
       "91    False     False            True           True            True   \n",
       "92     True     False           False          False           False   \n",
       "93     True     False            True           True            True   \n",
       "94    False      True           False          False           False   \n",
       "95    False      True            True           True            True   \n",
       "\n",
       "    f1_train  weighted_f1_train  accuracy_train   f1_test  weighted_f1_test  \\\n",
       "0   0.997881           0.997881        0.997881  0.977923          0.977923   \n",
       "1   0.968533           0.968533        0.968533  0.948729          0.948729   \n",
       "2   0.999366           0.999366        0.999366  0.975388          0.975388   \n",
       "3   0.951599           0.951599        0.951599  0.930159          0.930159   \n",
       "4   0.999366           0.999366        0.999366  0.972834          0.972834   \n",
       "..       ...                ...             ...       ...               ...   \n",
       "91  1.000000           1.000000        1.000000  0.962286          0.962286   \n",
       "92  1.000000           1.000000        1.000000  0.959620          0.959620   \n",
       "93  1.000000           1.000000        1.000000  0.959620          0.959620   \n",
       "94  1.000000           1.000000        1.000000  0.951487          0.951487   \n",
       "95  1.000000           1.000000        1.000000  0.954222          0.954222   \n",
       "\n",
       "    accuracy_test  \n",
       "0        0.977923  \n",
       "1        0.948729  \n",
       "2        0.975388  \n",
       "3        0.930159  \n",
       "4        0.972834  \n",
       "..            ...  \n",
       "91       0.962286  \n",
       "92       0.959620  \n",
       "93       0.959620  \n",
       "94       0.951487  \n",
       "95       0.954222  \n",
       "\n",
       "[96 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model for Weighted F1 on Train Set:\n",
      "            model_type  weighted_f1_train\n",
      "2   LogisticRegression           0.999366\n",
      "48        RandomForest           1.000000\n"
     ]
    }
   ],
   "source": [
    "# (E) Which model has the best weighted f1 according to the train set?\n",
    "best_model_train = results_df.loc[results_df.groupby('model_type')['weighted_f1_train'].idxmax()]\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Model for Weighted F1 on Train Set:\")\n",
    "print(best_model_train[['model_type', 'weighted_f1_train']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** has the best weighted f1 according to the **train set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model for Weighted F1 on Test Set:\n",
      "            model_type  weighted_f1_test\n",
      "0   LogisticRegression          0.977923\n",
      "48        RandomForest          0.968857\n"
     ]
    }
   ],
   "source": [
    "# (E) Which model has the best weighted f1 according to the test set?\n",
    "best_model_test = results_df.loc[results_df.groupby('model_type')['weighted_f1_test'].idxmax()]\n",
    "\n",
    "print(\"\\nBest Model for Weighted F1 on Test Set:\")\n",
    "print(best_model_test[['model_type', 'weighted_f1_test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** has the best weighted f1 according to the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_type           LogisticRegression\n",
      "lowercased                        False\n",
      "stopwords_removed                 False\n",
      "lemmatized                        False\n",
      "unigrams                           True\n",
      "bigrams                           False\n",
      "trigrams                          False\n",
      "tfidf_unigrams                    False\n",
      "tfidf_bigrams                     False\n",
      "tfidf_trigrams                    False\n",
      "f1_train                       0.997881\n",
      "weighted_f1_train              0.997881\n",
      "accuracy_train                 0.997881\n",
      "f1_test                        0.977923\n",
      "weighted_f1_test               0.977923\n",
      "accuracy_test                  0.977923\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best_model_q1 = results_df.loc[0]\n",
    "print(results_df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[698,   1],\n",
       "       [ 17, 120]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (F)[4 points]\n",
    "# Show the confusion matrix for the best-performing model on the test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cleaned_train_text = preprocess(X_train, lowercase=False, remove_stopwords=False, lemmatize=False)\n",
    "cleaned_test_text = preprocess(X_test, lowercase=False, remove_stopwords=False, lemmatize=False)\n",
    "train_features, test_features = extract_features(cleaned_train_text, cleaned_test_text, tfidf_option=False, ngram_range=(1,1))\n",
    "\n",
    "model = train_model('LogisticRegression', train_features, y_train)\n",
    "y_pred = model.predict(test_features)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what each element of the matrix means:\n",
    "\n",
    "- **Top Left:** True Positives (TP): Spam messages that are correctly predicted as spam\n",
    "- **Top Right:** False Negatives (FN): Spam messages that are incorrectly predicted as not spam\n",
    "- **Bottom Left:** False Positives (FP): Non-spam messages that are incorrectly predicted as spam\n",
    "- **Bottom Right:** True Negatives (TN): Non-spam messages that are correctly predicted as not spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (56 points)\n",
    "**(A)[40 points]** Repeat the experiment for the best-performing combination of model type, preprocessing, and lexical features above, but this time limit the analysis to all the combinations of the parts-of-speeches below (total of 8 combinations):<br>\n",
    "\n",
    "(1) Adjectives <br>\n",
    "(2) Nouns  <br>\n",
    "(3) Verbs  <br>\n",
    "\n",
    "What this means is that after tokenization and before preprocessing, you remove all words that do not have the part of speech you are looking at. E.g., for the combination Adjectives & Nouns, all words that are not a noun or adjective should be removed. <br>\n",
    "\n",
    "So that's 8 new models. <br>\n",
    "\n",
    "**(B)[10 points]** Create a new dataframe where each row is one of the models. The dataframe should have 3 boolean columns capturing which parts-of-speech were used: <br>\n",
    "\n",
    "(1) adjectives : 1 / 0 <br>\n",
    "(2) nouns : 1 / 0 <br>\n",
    "(3) verbs : 1 / 0 <br>\n",
    " \n",
    "and 3 columns showing the default f1 (default parameters), weighted f1, and accuracy of the models on the **test** set only: <br>\n",
    "\n",
    "(4) f1_test <br>\n",
    "(5) weighted_f1_test <br>\n",
    "(6) accuracy_test <br>\n",
    "\n",
    "**(C)[6 points]** <br>\n",
    "Which model has the best weighted f1 according to the test set? <br>\n",
    "Show the confusion matrix for the best-performing model on the test set. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ivoryang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load data into a DataFrame\n",
    "data = pd.read_csv('SPAM.csv')\n",
    "\n",
    "# Convert 'spam' category to 1 and 'ham' category to 0\n",
    "data['Category'] = data['Category'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.15, random_state=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def pos_limit(tokenized_text, inc_adj=False, inc_noun=False, inc_verb=False):\n",
    "    # initialize an empty list to store the preprocessed text\n",
    "    cleaned_tokenized_text = []\n",
    "\n",
    "    # filter based on POS tags\n",
    "    if not inc_adj and not inc_noun and not inc_verb:\n",
    "        tagged_tokens = pos_tag(tokenized_text)\n",
    "        cleaned_tokenized_text = [token for token, pos in tagged_tokens if not pos.startswith('JJ') and not pos.startswith('NN') and not pos.startswith('VB')]\n",
    "    else:\n",
    "        allowed_pos = []\n",
    "        if inc_adj:\n",
    "            # Used example usage commented out below to check if VB would cover VBZ as well, and it does\n",
    "            # So only included the first two characters like JJ, NN and VB\n",
    "            # JJ, JJR, JJS \n",
    "            allowed_pos.append('JJ')\n",
    "        if inc_noun:\n",
    "            # NN, NNS, NNP, NNPS\n",
    "            allowed_pos.append('NN')\n",
    "        if inc_verb:\n",
    "            # VB, VBD, VBN, VBP, VBZ\n",
    "            allowed_pos.append('VB')\n",
    "\n",
    "        tagged_tokens = pos_tag(tokenized_text)\n",
    "        cleaned_tokenized_text = [token for token, pos in tagged_tokens if pos.startswith(tuple(allowed_pos))]\n",
    "\n",
    "    return cleaned_tokenized_text\n",
    "\n",
    "# Example usage:\n",
    "# tokenized_text = [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
    "# print(pos_tag(tokenized_text))\n",
    "# preprocessed_text = pos_limit(tokenized_text, inc_adj=False, inc_noun=False, inc_verb=False)\n",
    "\n",
    "# print(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pos_experiments():\n",
    "    results_pos = []\n",
    "\n",
    "    pos_combinations = [\n",
    "        {'adjectives': True, 'nouns': False, 'verbs': False},  # Adjectives only\n",
    "        {'adjectives': False, 'nouns': True, 'verbs': False},  # Nouns only\n",
    "        {'adjectives': False, 'nouns': False, 'verbs': True},  # Verbs only\n",
    "        {'adjectives': True, 'nouns': True, 'verbs': False},   # Adjectives & Nouns\n",
    "        {'adjectives': True, 'nouns': False, 'verbs': True},   # Adjectives & Verbs\n",
    "        {'adjectives': False, 'nouns': True, 'verbs': True},   # Nouns & Verbs\n",
    "        {'adjectives': True, 'nouns': True, 'verbs': True},    # Adjectives, Nouns & Verbs\n",
    "        {'adjectives': False, 'nouns': False, 'verbs': False}  # Baseline without filtering\n",
    "    ]\n",
    "\n",
    "    for pos_config in pos_combinations:\n",
    "        train_features_pos = [' '.join(pos_limit(word_tokenize(text), inc_adj=pos_config['adjectives'], inc_noun=pos_config['nouns'], inc_verb=pos_config['verbs'])) for text in X_train]\n",
    "        test_features_pos = [' '.join(pos_limit(word_tokenize(text), inc_adj=pos_config['adjectives'], inc_noun=pos_config['nouns'], inc_verb=pos_config['verbs'])) for text in X_test]\n",
    "\n",
    "        # Check if filtered text is empty\n",
    "        if not any(train_features_pos) or not any(test_features_pos):\n",
    "            continue\n",
    "\n",
    "        vectorizer = CountVectorizer(ngram_range=(1, 1), lowercase=False)\n",
    "        features_train = vectorizer.fit_transform(train_features_pos)\n",
    "        features_test = vectorizer.transform(test_features_pos)\n",
    "\n",
    "        model_pos = LogisticRegression(random_state=27)\n",
    "        model_pos.fit(features_train, y_train)\n",
    "        y_pred_pos = model_pos.predict(features_test)\n",
    "\n",
    "        f1_test_pos = f1_score(y_test, y_pred_pos)\n",
    "        weighted_f1_test_pos = f1_score(y_test, y_pred_pos, average='weighted')\n",
    "        accuracy_test_pos = accuracy_score(y_test, y_pred_pos)\n",
    "\n",
    "        result_row_pos = {\n",
    "            'adjectives': pos_config['adjectives'],\n",
    "            'nouns': pos_config['nouns'],\n",
    "            'verbs': pos_config['verbs'],\n",
    "            'f1_test': f1_test_pos,\n",
    "            'weighted_f1_test': weighted_f1_test_pos,\n",
    "            'accuracy_test': accuracy_test_pos\n",
    "        }\n",
    "        results_pos.append(result_row_pos)\n",
    "\n",
    "    results_pos_df = pd.DataFrame(results_pos)\n",
    "    return results_pos_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   adjectives  nouns  verbs   f1_test  weighted_f1_test  accuracy_test\n",
      "0        True  False  False  0.574359          0.883262       0.900718\n",
      "1       False   True  False  0.864198          0.958437       0.960526\n",
      "2       False  False   True  0.640777          0.898927       0.911483\n",
      "3        True   True  False  0.895161          0.967553       0.968900\n",
      "4        True  False   True  0.752212          0.927013       0.933014\n",
      "5       False   True   True  0.891566          0.966366       0.967703\n",
      "6        True   True   True  0.916996          0.974024       0.974880\n",
      "7       False  False  False  0.788136          0.936168       0.940191\n"
     ]
    }
   ],
   "source": [
    "results_pos_df = run_pos_experiments()\n",
    "print(results_pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>0.883262</td>\n",
       "      <td>0.900718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.958437</td>\n",
       "      <td>0.960526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.898927</td>\n",
       "      <td>0.911483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>0.967553</td>\n",
       "      <td>0.968900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.927013</td>\n",
       "      <td>0.933014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.966366</td>\n",
       "      <td>0.967703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.916996</td>\n",
       "      <td>0.974024</td>\n",
       "      <td>0.974880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.936168</td>\n",
       "      <td>0.940191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjectives  nouns  verbs   f1_test  weighted_f1_test  accuracy_test\n",
       "0        True  False  False  0.574359          0.883262       0.900718\n",
       "1       False   True  False  0.864198          0.958437       0.960526\n",
       "2       False  False   True  0.640777          0.898927       0.911483\n",
       "3        True   True  False  0.895161          0.967553       0.968900\n",
       "4        True  False   True  0.752212          0.927013       0.933014\n",
       "5       False   True   True  0.891566          0.966366       0.967703\n",
       "6        True   True   True  0.916996          0.974024       0.974880\n",
       "7       False  False  False  0.788136          0.936168       0.940191"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model:\n",
      "adjectives              True\n",
      "nouns                   True\n",
      "verbs                   True\n",
      "f1_test             0.916996\n",
      "weighted_f1_test    0.974024\n",
      "accuracy_test        0.97488\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# C: Which model has the best weighted f1 according to the test set?\n",
    "\n",
    "# Find the model with the best weighted f1\n",
    "best_model_q2 = results_pos_df.loc[results_pos_df['weighted_f1_test'].idxmax()]\n",
    "\n",
    "# Print the information about the best model\n",
    "print(\"\\nBest Model:\")\n",
    "print(best_model_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[699   0]\n",
      " [ 42  95]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Best model configuration\n",
    "best_model_config = {'adjectives': True, 'nouns': True, 'verbs': True}\n",
    "\n",
    "# Preprocess the test data with the best model's configuration\n",
    "X_test_processed_pos = [' '.join(pos_limit(word_tokenize(text), inc_adj=best_model_config['adjectives'], inc_noun=best_model_config['nouns'], inc_verb=best_model_config['verbs'])) for text in X_test]\n",
    "\n",
    "# Vectorize the training features\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), lowercase=False)\n",
    "features_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Vectorize the test features using the vocabulary from the training data\n",
    "features_test = vectorizer.transform(X_test_processed_pos)\n",
    "\n",
    "# Train a logistic regression model on the training features\n",
    "model_pos = LogisticRegression(random_state=27)\n",
    "model_pos.fit(features_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_test = model_pos.predict(features_test)\n",
    "\n",
    "# Show the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (68 points)\n",
    "\n",
    "**(A)[32 points]** Repeat the experiment for the best-performing model type from Q1 (i.e., LR or RF) using the following features (no preprocessing is required): <br>\n",
    "(1) Word2Vec features from GoogleNews (limit vocabulary to 40000 words) <br>\n",
    "(2) Features from a new Word2Vec model trained on the **train** set of your dataset. Use the following hyperparameters: window=5,vector_size=100 ,min_count=5 <br>\n",
    "\n",
    "You can average the semantic embeddings for the words in a document to create a single semantic vector for the document. You can ignore words that are not present in your Word2Vec model. <br>\n",
    "\n",
    "**(B)[10 points]** Use weighted f1 on the test set to pick the best semantic features from the two options above and combine them with the best-performing features from Q2 to train a new model. <br>\n",
    "\n",
    "**(C)[20 points]** Finally, create a new dataframe where each row is one of the following models: <br>\n",
    "(1) Best-performing model using lexical features only (Q1).  <br>\n",
    "(2) Best-performing model using lexical features on different parts-of-speech (Q2).  <br>\n",
    "(3) Best-performing model from using semantic features only (Q3-A).  <br>\n",
    "(4) The final model from Q3-B that combines the best semantic and lexical features.  <br>\n",
    "\n",
    "<br>\n",
    "The dataframe should have boolean columns capturing which (if any) preprocessing techniques were used: <br>\n",
    "<br>\n",
    "\n",
    "(1) lowercased: 1 / 0 <br>\n",
    "(2) stopwords_removed: 1 / 0 <br>\n",
    "(3) lemmatized: 1 / 0 <br>\n",
    "\n",
    "<br>\n",
    "which (if any) parts-of-speech were used: <br>\n",
    "<br>\n",
    "\n",
    "(4) adjectives : 1 / 0 <br>\n",
    "(5) nouns : 1 / 0 <br>\n",
    "(6) verbs : 1 / 0 <br>\n",
    "(7) all: 1 / 0  (this is for the best-performing Q1 model that uses all parts-of-speech)<br>\n",
    "\n",
    "\n",
    "<br>\n",
    "which (if any) lexical features were used: <br>\n",
    "<br>\n",
    "\n",
    "(8) unigrams : 1 / 0 <br>\n",
    "(9) bigrams :  1 / 0 <br>\n",
    "(10) trigrams :  1 / 0 <br>\n",
    "(11) tfidf unigrams :  1 / 0 <br>\n",
    "(12) tfidf bigrams :  1 / 0 <br>\n",
    "(13) tfidf trigrams :  1 / 0 <br>\n",
    "\n",
    "\n",
    "<br>\n",
    "which (if any) semantic features were used: <br>\n",
    "<br>\n",
    "\n",
    "(14) w2v_GoogleNews : 1 / 0 <br>\n",
    "(15) w2v_Span=m : 1 / 0 <br>\n",
    "\n",
    " \n",
    "and 3 columns showing the default f1 (default parameters), weighted f1, and accuracy of the four models on the **test** set only: <br>\n",
    "\n",
    "(16) f1_test <br>\n",
    "(17) weighted_f1_test <br>\n",
    "(18) accuracy_test <br>\n",
    "\n",
    "**(D)[6 points]**\n",
    "Which model has the best weighted f1 according to the test set? <br> \n",
    "Show the confusion matrix for the best-performing model on the test set. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Load the GoogleNews Word2Vec model\n",
    "google_w2v_model_path = '/Users/ivoryang/Downloads/GoogleNews-vectors-negative300.bin'\n",
    "google_w2v_model = KeyedVectors.load_word2vec_format(google_w2v_model_path, binary=True, limit=40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text in training set\n",
    "train_data, test_data = train_test_split(data, test_size=0.15, random_state = 27)\n",
    "\n",
    "# Extract raw text and labels\n",
    "X_train_raw = train_data['Message']\n",
    "y_train = train_data['Category']\n",
    "X_test_raw = test_data['Message']\n",
    "y_test = test_data['Category']\n",
    "\n",
    "train_texts = [word_tokenize(text) for text in X_train_raw]\n",
    "\n",
    "# Train a new Word2Vec model on the training set\n",
    "my_model = Word2Vec(sentences=train_texts, vector_size=100, window=5, min_count=5).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_w2v=[{'name':'w2v_GoogleNews', 'model': google_w2v_model}, {'name':'w2v_Span=m', 'model':my_model}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_w2v_features(text, w2vmodel):\n",
    "    tokens = word_tokenize(text)\n",
    "    vectors = [w2vmodel[word] for word in tokens if w2vmodel.has_index_for(word)]\n",
    "    \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2vmodel.vector_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model   f1_test  weighted_f1_test  accuracy_test\n",
      "0  w2v_GoogleNews  0.854902           0.95439       0.955742\n",
      "            Model   f1_test  weighted_f1_test  accuracy_test\n",
      "0  w2v_GoogleNews  0.854902          0.954390       0.955742\n",
      "1      w2v_Span=m  0.142857          0.786829       0.842105\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "i = 1\n",
    "total_iterations = len(models_w2v)\n",
    "    \n",
    "for wv in models_w2v:\n",
    "    wv_name = wv['name']\n",
    "    word2vec = wv['model']\n",
    "\n",
    "    # Preprocess the training data\n",
    "    X_train_processed = [extract_w2v_features(text, word2vec) for text in X_train_raw]\n",
    "\n",
    "    # Convert the list of feature vectors to a numpy array\n",
    "    X_train_array = np.array(X_train_processed)\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    logreg_model = LogisticRegression(random_state=27)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    logreg_model.fit(X_train_array, y_train)\n",
    "\n",
    "    # Preprocess the test data\n",
    "    X_test_processed = [extract_w2v_features(text, word2vec) for text in X_test_raw]\n",
    "\n",
    "    # Convert the list of feature vectors to a numpy array\n",
    "    X_test_array = np.array(X_test_processed)\n",
    "\n",
    "    # Predict using the test data\n",
    "    y_pred = logreg_model.predict(X_test_array)\n",
    "\n",
    "    # Calculate and print evaluation metrics\n",
    "    f1_test = f1_score(y_test, y_pred)\n",
    "    weighted_f1_test = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    metrics_list.append({\n",
    "        'Model': wv_name,\n",
    "        'f1_test': f1_test,\n",
    "        'weighted_f1_test': weighted_f1_test,\n",
    "        'accuracy_test': accuracy_test\n",
    "    })\n",
    "    \n",
    "    # Create a DataFrame from the list of metrics\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_GoogleNews</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.954390</td>\n",
       "      <td>0.955742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_Span=m</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.786829</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model   f1_test  weighted_f1_test  accuracy_test\n",
       "0  w2v_GoogleNews  0.854902          0.954390       0.955742\n",
       "1      w2v_Span=m  0.142857          0.786829       0.842105"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Performing Model:\n",
      "Model               w2v_GoogleNews\n",
      "f1_test                   0.854902\n",
      "weighted_f1_test           0.95439\n",
      "accuracy_test             0.955742\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by 'Weighted F1 Score on Test Data' column in descending order\n",
    "sorted_df = metrics_df.sort_values(by='weighted_f1_test', ascending=False)\n",
    "\n",
    "# Select the top-performing model (first row)\n",
    "best_model_q3a = sorted_df.iloc[0]\n",
    "\n",
    "# Display the top-performing model\n",
    "print(\"Top Performing Model:\")\n",
    "print(best_model_q3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    f1_test  weighted_f1_test  accuracy_test\n",
      "0  0.829457          0.946034       0.947368\n"
     ]
    }
   ],
   "source": [
    "# B\n",
    "\n",
    "# From Q2\n",
    "\n",
    "combined_metrics_list = []\n",
    "\n",
    "best_model_config = {'adjectives': True, 'nouns': True, 'verbs': True}\n",
    "\n",
    "# Extract the relevant configuration values\n",
    "inc_adj = best_model_config['adjectives']\n",
    "inc_noun = best_model_config['nouns']\n",
    "inc_verb = best_model_config['verbs']\n",
    "\n",
    "# Preprocess the training data with the Q2 model's configuration\n",
    "X_train_processed_pos = [' '.join(pos_limit(word_tokenize(text), inc_adj=inc_adj, inc_noun=inc_noun, inc_verb=inc_verb)) for text in X_train_raw]\n",
    "# Preprocess the test data with the Q2 model's configuration\n",
    "X_test_processed_pos = [' '.join(pos_limit(word_tokenize(text), inc_adj=inc_adj, inc_noun=inc_noun, inc_verb=inc_verb)) for text in X_test_raw]\n",
    "\n",
    "# Load the GoogleNews Word2Vec model\n",
    "google_w2v_model_path = '/Users/ivoryang/Downloads/GoogleNews-vectors-negative300.bin'\n",
    "google_w2v_model = KeyedVectors.load_word2vec_format(google_w2v_model_path, binary=True, limit=40000)\n",
    "\n",
    "# Train a new Word2Vec model on the training set\n",
    "train_texts = [word_tokenize(text) for text in X_train_raw]\n",
    "my_model = Word2Vec(sentences=train_texts, vector_size=100, window=5, min_count=5).wv\n",
    "\n",
    "# Extract semantic features\n",
    "X_train_w2v_GoogleNews = [extract_w2v_features(text, google_w2v_model) for text in X_train_processed_pos]\n",
    "X_test_w2v_GoogleNews = [extract_w2v_features(text, google_w2v_model) for text in X_test_processed_pos]\n",
    "\n",
    "X_train_w2v_Span_m = [extract_w2v_features(text, my_model) for text in X_train_processed_pos]\n",
    "X_test_w2v_Span_m = [extract_w2v_features(text, my_model) for text in X_test_processed_pos]\n",
    "\n",
    "# Combine Q2 features with the new semantic features\n",
    "X_train_combined = np.column_stack((X_train_w2v_GoogleNews, X_train_w2v_Span_m))\n",
    "X_test_combined = np.column_stack((X_test_w2v_GoogleNews, X_test_w2v_Span_m))\n",
    "\n",
    "# Train a new model (e.g., Logistic Regression) on the combined features\n",
    "new_combined_model = LogisticRegression(random_state=42)\n",
    "new_combined_model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict using the combined features\n",
    "y_pred_combined = new_combined_model.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the new combined model\n",
    "f1_test_combined = f1_score(y_test, y_pred_combined)\n",
    "weighted_f1_test_combined = f1_score(y_test, y_pred_combined, average='weighted')\n",
    "accuracy_test_combined = accuracy_score(y_test, y_pred_combined)\n",
    "\n",
    "\n",
    "combined_metrics_list.append({\n",
    "        'f1_test': f1_test_combined,\n",
    "        'weighted_f1_test': weighted_f1_test_combined,\n",
    "        'accuracy_test': accuracy_test_combined\n",
    "    })\n",
    "    \n",
    "# Create a DataFrame from the list of metrics\n",
    "combined_metrics_df = pd.DataFrame(combined_metrics_list)\n",
    "print(combined_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.946034</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_test  weighted_f1_test  accuracy_test\n",
       "0  0.829457          0.946034       0.947368"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_q3b = combined_metrics_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lowercased  stopwords_removed  lemmatized  adjectives  nouns  verbs  all  \\\n",
      "0           0                  0           0           0      0      0    0   \n",
      "1           0                  0           0           1      1      1    0   \n",
      "2           0                  0           0           0      0      0    0   \n",
      "3           0                  0           0           1      1      1    0   \n",
      "\n",
      "   unigrams  bigrams  trigrams  tfidf_unigrams  tfidf_bigrams  tfidf_trigrams  \\\n",
      "0         1        0         0               0              0               0   \n",
      "1         1        0         0               0              0               0   \n",
      "2         0        0         0               0              0               0   \n",
      "3         1        0         0               0              0               0   \n",
      "\n",
      "   w2v_GoogleNews  w2v_Span=m   f1_test  weighted_f1_test  accuracy_test  \n",
      "0               0           0  0.977923          0.977923       0.977923  \n",
      "1               0           0  0.916996          0.974024       0.974880  \n",
      "2               1           0  0.854902          0.954390       0.955742  \n",
      "3               1           0  0.829457          0.946034       0.947368  \n"
     ]
    }
   ],
   "source": [
    "# (C) Create a new dataframe with models and features\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Bring in metrics from previous questions\n",
    "q1_metrics = {'f1_test': best_model_q1['f1_test'],\n",
    "              'weighted_f1_test': best_model_q1['weighted_f1_test'],\n",
    "              'accuracy_test': best_model_q1['accuracy_test']}\n",
    "\n",
    "q2_metrics = {'f1_test': best_model_q2['f1_test'],\n",
    "              'weighted_f1_test': best_model_q2['weighted_f1_test'],\n",
    "              'accuracy_test': best_model_q2['accuracy_test']}\n",
    "\n",
    "q3a_metrics = {'f1_test': best_model_q3a['f1_test'],\n",
    "               'weighted_f1_test': best_model_q3a['weighted_f1_test'],\n",
    "               'accuracy_test': best_model_q3a['accuracy_test']}\n",
    "\n",
    "q3b_metrics = {'f1_test': best_model_q3b['f1_test'],\n",
    "               'weighted_f1_test': best_model_q3b['weighted_f1_test'],\n",
    "               'accuracy_test': best_model_q3b['accuracy_test']}\n",
    "\n",
    "\n",
    "# Create a DataFrame with the provided metrics\n",
    "data = {\n",
    "    'lowercased': [0, 0, 0, 0],\n",
    "    'stopwords_removed': [0, 0, 0, 0],\n",
    "    'lemmatized': [0, 0, 0, 0],\n",
    "    'adjectives': [0, 1, 0, 1],\n",
    "    'nouns': [0, 1, 0, 1],\n",
    "    'verbs': [0, 1, 0, 1],\n",
    "    'all': [0, 0, 0, 0],\n",
    "    'unigrams': [1, 1, 0, 1],\n",
    "    'bigrams': [0, 0, 0, 0],\n",
    "    'trigrams': [0, 0, 0, 0],\n",
    "    'tfidf_unigrams': [0, 0, 0, 0],\n",
    "    'tfidf_bigrams': [0, 0, 0, 0],\n",
    "    'tfidf_trigrams': [0, 0, 0, 0],\n",
    "    'w2v_GoogleNews': [0, 0, 1, 1],\n",
    "    'w2v_Span=m': [0, 0, 0, 0],\n",
    "    'f1_test': [q1_metrics['f1_test'], q2_metrics['f1_test'], q3a_metrics['f1_test'], q3b_metrics['f1_test']],\n",
    "    'weighted_f1_test': [q1_metrics['weighted_f1_test'], q2_metrics['weighted_f1_test'], q3a_metrics['weighted_f1_test'], q3b_metrics['weighted_f1_test']],\n",
    "    'accuracy_test': [q1_metrics['accuracy_test'], q2_metrics['accuracy_test'], q3a_metrics['accuracy_test'], q3b_metrics['accuracy_test']],\n",
    "}\n",
    "\n",
    "\n",
    "df4 = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowercased</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>all</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>tfidf_unigrams</th>\n",
       "      <th>tfidf_bigrams</th>\n",
       "      <th>tfidf_trigrams</th>\n",
       "      <th>w2v_GoogleNews</th>\n",
       "      <th>w2v_Span=m</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>weighted_f1_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>0.977923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916996</td>\n",
       "      <td>0.974024</td>\n",
       "      <td>0.974880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.954390</td>\n",
       "      <td>0.955742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.946034</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lowercased  stopwords_removed  lemmatized  adjectives  nouns  verbs  all  \\\n",
       "0           0                  0           0           0      0      0    0   \n",
       "1           0                  0           0           1      1      1    0   \n",
       "2           0                  0           0           0      0      0    0   \n",
       "3           0                  0           0           1      1      1    0   \n",
       "\n",
       "   unigrams  bigrams  trigrams  tfidf_unigrams  tfidf_bigrams  tfidf_trigrams  \\\n",
       "0         1        0         0               0              0               0   \n",
       "1         1        0         0               0              0               0   \n",
       "2         0        0         0               0              0               0   \n",
       "3         1        0         0               0              0               0   \n",
       "\n",
       "   w2v_GoogleNews  w2v_Span=m   f1_test  weighted_f1_test  accuracy_test  \n",
       "0               0           0  0.977923          0.977923       0.977923  \n",
       "1               0           0  0.916996          0.974024       0.974880  \n",
       "2               1           0  0.854902          0.954390       0.955742  \n",
       "3               1           0  0.829457          0.946034       0.947368  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowercased           0.000000\n",
      "stopwords_removed    0.000000\n",
      "lemmatized           0.000000\n",
      "adjectives           0.000000\n",
      "nouns                0.000000\n",
      "verbs                0.000000\n",
      "all                  0.000000\n",
      "unigrams             1.000000\n",
      "bigrams              0.000000\n",
      "trigrams             0.000000\n",
      "tfidf_unigrams       0.000000\n",
      "tfidf_bigrams        0.000000\n",
      "tfidf_trigrams       0.000000\n",
      "w2v_GoogleNews       0.000000\n",
      "w2v_Span=m           0.000000\n",
      "f1_test              0.977923\n",
      "weighted_f1_test     0.977923\n",
      "accuracy_test        0.977923\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# (D)[6 points] Which model has the best weighted f1 according to the test set?\n",
    "\n",
    "# Sort the DataFrame by 'Weighted F1 Score' column in descending order\n",
    "sorted_df4 = df4.sort_values(by='weighted_f1_test', ascending=False)\n",
    "\n",
    "# Select the top-performing model (first row)\n",
    "top_overall_model = sorted_df4.iloc[0]\n",
    "\n",
    "print(top_overall_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model appears to be the model from Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[698,   1],\n",
       "       [ 17, 120]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the confusion matrix for the best-performing model on the test set.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cleaned_train_text = preprocess(X_train, lowercase=False, remove_stopwords=False, lemmatize=False)\n",
    "cleaned_test_text = preprocess(X_test, lowercase=False, remove_stopwords=False, lemmatize=False)\n",
    "train_features, test_features = extract_features(cleaned_train_text, cleaned_test_text, tfidf_option=False, ngram_range=(1,1))\n",
    "\n",
    "model = train_model('LogisticRegression', train_features, y_train)\n",
    "y_pred = model.predict(test_features)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS (5 to 50 points)\n",
    "\n",
    "Find a combination of preprocessing, features, and models that outperforms the best model above (using weighted f1 as the metric). Your bonus points is based on how well you rank in the class. We will use the curve below to distribute the bonus points. I.e., the top 5% of the class will receive 50 bonus points and the bottom 5% will receive 5 bonus points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler  # Add this line\n",
    "# Load data into a dataframe\n",
    "data = pd.read_csv('SPAM.csv')\n",
    "\n",
    "# Convert spam category to 1 and ham category to 0\n",
    "data['Category'] = data['Category'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Divide the data into a random train/test set with a ratio of 85/15\n",
    "X = data['Message']\n",
    "y = data['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts, lowercase=False, remove_stopwords=False, lemmatize=False, include_pos = True):\n",
    "    cleaned_texts = []\n",
    "    \n",
    "    for text in texts:\n",
    "        tokens = word_tokenize(text)\n",
    "        cleaned_tokens = []\n",
    "        \n",
    "        for token, pos in pos_tag(tokens):\n",
    "            # Lowercase\n",
    "            if lowercase:\n",
    "                token = token.lower()\n",
    "\n",
    "            # Remove stopwords\n",
    "            if remove_stopwords:\n",
    "                if token not in stopwords.words('english'):\n",
    "                    cleaned_tokens.append(token)\n",
    "            else:\n",
    "                cleaned_tokens.append(token)\n",
    "\n",
    "            # Lemmatize\n",
    "            if lemmatize:\n",
    "                lemmatizer = WordNetLemmatizer()\n",
    "                token = lemmatizer.lemmatize(token)\n",
    "\n",
    "            # Include only specific POS\n",
    "            if include_pos:\n",
    "                if pos.startswith(include_pos):\n",
    "                    cleaned_tokens.append(token)\n",
    "\n",
    "        cleaned_texts.append(' '.join(cleaned_tokens))\n",
    "\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "X_train_processed = preprocess(X_train, lowercase=False, remove_stopwords=False, lemmatize=False, include_pos='NVAJ')\n",
    "\n",
    "# Vectorize the text features using CountVectorizer with unigrams only\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), lowercase=False)\n",
    "features_train = vectorizer.fit_transform(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Logistic Regression with GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': [101, 500, 4000],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=27), param_grid, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search.fit(features_train, y_train)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test data\n",
    "X_test_processed = preprocess(X_test, lowercase=False, remove_stopwords=False, lemmatize=False, include_pos='NVAJ')\n",
    "features_test = vectorizer.transform(X_test_processed)\n",
    "\n",
    "# Predict using the test data\n",
    "y_pred = best_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "f1_test_count = f1_score(y_test, y_pred)\n",
    "weighted_f1_test_count = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy_test_count = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Store evaluation metrics for selected features\n",
    "metrics_list_count = [{\n",
    "    'Model': 'LogisticRegression',\n",
    "    'f1_test': f1_test_count,\n",
    "    'weighted_f1_test': weighted_f1_test_count,\n",
    "    'accuracy_test': accuracy_test_count\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Model': 'LogisticRegression', 'f1_test': 0.9438202247191011, 'weighted_f1_test': 0.9818669106872723, 'accuracy_test': 0.9820574162679426}]\n"
     ]
    }
   ],
   "source": [
    "# Print or use the evaluation metrics as needed\n",
    "print(metrics_list_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'LogisticRegression',\n",
       "  'f1_test': 0.9438202247191011,\n",
       "  'weighted_f1_test': 0.9818669106872723,\n",
       "  'accuracy_test': 0.9820574162679426}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best after using grid search\n",
    "\n",
    "metrics_list_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAG1CAYAAAAMU3WaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABI4UlEQVR4nO3de3zPdf/H8cfXDl8b2xx3YpZjJSaRc85EcjlcXSoqfg5RErlEuIqESVG6uFSUDtJ0wKWTQ7EhlNNqKOlyWrHW5bA5btjn98f78rWZ02bb5/vdnvfb7XPb5/v5fPb9vt6W9vT5vA8Oy7IsRERERDxUMbsLEBEREbkRCjMiIiLi0RRmRERExKMpzIiIiIhHU5gRERERj6YwIyIiIh5NYUZEREQ8msKMiIiIeDSFGREREfFoCjMiIiLi0dwmzERHR+NwOBg2bJjrWJ8+fXA4HFm2Ro0a2VekiIiIuB1vuwsA2LRpE2+++SZRUVHZznXo0IF58+a5Xvv6+hZkaSIiIuLmbA8zJ06coFevXsyZM4eJEydmO+90OgkNDc31+2dkZHDw4EECAgJwOBw3UqqIiIgUEMuyOH78OOHh4RQrdvUHSbaHmcGDB9OpUyfatm172TATGxtLcHAwpUqVokWLFkyaNIng4OArvl9aWhppaWmu17///js1a9bMl9pFREQkfyUmJlKxYsWrXmNrmImJiWHr1q1s2rTpsuc7duzI3/72NyIjI9m7dy/PPvssrVu3ZsuWLTidzst+T3R0NM8//3y244mBgQTGx0PZsnnZBBEREckHqampREREEBAQcM1rHZZlWQVQUzaJiYnUr1+fFStWUKdOHQBatmzJ7bffzquvvnrZ7zl06BCRkZHExMTQvXv3y15z6Z2ZC38YKUDg4MEwc2ZeN0VERETyWGpqKkFBQaSkpBAYGHjVa20bzbRlyxaSk5OpV68e3t7eeHt7ExcXx2uvvYa3tzfnz5/P9j1hYWFERkaye/fuK76v0+kkMDAwy+by+uuwY0d+NEdERERsYluYadOmDQkJCcTHx7u2+vXr06tXL+Lj4/Hy8sr2PYcPHyYxMZGwsLCcf+C998L58zB8ONhzM0pERETygW1hJiAggFq1amXZSpQoQdmyZalVqxYnTpxgxIgRbNiwgX379hEbG0vnzp0pV64c3bp1y/kHvvAC+PjAihXw1Vd53yARERGxhdtMmncpLy8vEhIS6NKlCzVq1KB3797UqFGDDRs2XFdnoGyqVIGhQ83+8OFw9mzeFiwiIiK2sK0DcEHJ0oHIsqB6dfjzT3jtNRgyxO7yRERE5DI8ogOwLYKCzOMmgHHj4MgRe+sRERGRG1a0wgxAv35QuzYcPQqXmY9GREREPEvRCzPe3vDKK2Z/1iz46Sd76xEREZEbUvTCDECbNvCXv5ih2iNG2F2NiIiI3ICiGWYAXnrJ3KX58ktYvtzuakRERCSXim6YqVHj4mim4cPh3Dl76xEREZFcKbphBuDZZ83Ckzt3wptv2l2NiIiI5ELRDjOlS8OECWb/uefMCCcRERHxKEU7zAA8+ijUrAmHD1+cg0ZEREQ8hsJM5qHa//wn/PKLvfWIiIhIjijMALRvD/fcYzoBa6i2iIiIR1GYuWDaNPDygs8+g6+/trsaERERuU4KMxfccgsMHmz2n3pKQ7VFREQ8hMJMZuPGmRFO27fDW2/ZXY2IiIhcB4WZzMqUubj45D/+ASkp9tYjIiIi16Qwc6lBg8wjp//+FyZOtLsaERERuQaFmUv5+JjOwAAzZsCvv9pbj4iIiFyVwszldOwId98NZ8/CyJF2VyMiIiJXoTBzOQ7HxaHaixfD6tV2VyQiIiJXoDBzJbfdZvrPgBmqff68vfWIiIjIZSnMXM348VCqFPzwA8ybZ3c1IiIichkKM1dTrpxZTRtg7FhITbW3HhEREclGYeZaBg+G6tUhORkmT7a7GhEREbmEwsy1+PpeHKr9yiuwd6+99YiIiEgWCjPX4957oW1bSE/XUG0RERE3ozBzPRwOmD4dihWDTz6BNWvsrkhERET+R2HmetWuDY8+avaHDdNQbRERETehMJMTEyZAYCBs2wbvvWd3NSIiIoLCTM6ULw/PPmv2x4yB48ftrUdEREQUZnJsyBCoWhWSkuDFF+2uRkREpMhTmMkppxNeftnsv/wy7N9vbz0iIiJFnMJMbnTpAq1aQVoajBpldzUiIiJFmsJMbjgcZgI9hwMWLoRvv7W7IhERkSJLYSa36tSBfv3M/rBhkJFhazkiIiJFlcLMjZg4EQICYPNmmD/f7mpERESKJIWZGxESYlbTBhg9Gk6etLceERGRIshtwkx0dDQOh4Nhw4a5jlmWxfjx4wkPD8fPz4+WLVuyY8cO+4q8nKFDoXJlOHgQpk61uxoREZEixy3CzKZNm3jzzTeJiorKcnzq1KlMnz6dmTNnsmnTJkJDQ2nXrh3H3WmyuuLF4aWXzP7UqXDggL31iIiIFDG2h5kTJ07Qq1cv5syZQ+nSpV3HLcvi1VdfZezYsXTv3p1atWrx7rvvcurUKRYsWGBjxZfRvTs0bw5nzpjHTSIiIlJgbA8zgwcPplOnTrRt2zbL8b1795KUlET79u1dx5xOJy1atGD9+vVXfL+0tDRSU1OzbPnuwqraDgcsWAAbNuT/Z4qIiAhgc5iJiYlh69atREdHZzuXlJQEQEhISJbjISEhrnOXEx0dTVBQkGuLiIjI26KvpF496NPH7D/1lIZqi4iIFBDbwkxiYiJDhw5l/vz5FC9e/IrXORyOLK8ty8p2LLPRo0eTkpLi2hITE/Os5muaNAlKlIDvvoOYmIL7XBERkSLMtjCzZcsWkpOTqVevHt7e3nh7exMXF8drr72Gt7e3647MpXdhkpOTs92tyczpdBIYGJhlKzBhYWY1bTDLHGiotoiISL6zLcy0adOGhIQE4uPjXVv9+vXp1asX8fHxVKlShdDQUFauXOn6nvT0dOLi4mjSpIldZV/bU09BZCT89hs895zd1YiIiBR63nZ9cEBAALVq1cpyrESJEpQtW9Z1fNiwYUyePJnq1atTvXp1Jk+ejL+/Pz179rSj5Ovj5wezZsG998Krr0KPHtCwod1ViYiIFFq2hZnrMXLkSE6fPs3jjz/O0aNHadiwIStWrCAgIMDu0q6uUyfo1Qs++MCs37RlCziddlclIiJSKDksy7LsLiI/paamEhQUREpKSsH2n/nvf6FmTfjzTxg3DsaPL7jPFhER8XA5+f1t+zwzhVa5cvDPf5r9SZMgIcHeekRERAophZn81KMHdOkC585B377mq4iIiOQphZn85HDAv/4FQUGwebPpECwiIiJ5SmEmv4WHw7RpZv/ZZ+HXX+2tR0REpJBRmCkIfftCmzZmIcr+/bXUgYiISB5SmCkIDge8+Sb4+0NcHMyZY3dFIiIihYbCTEGpUsWMagJ4+mkoyDWjRERECjGFmYI0ZAg0agTHj8Njj0HhnuJHRESkQCjMFCQvL3jrLfD1hS++gAUL7K5IRETE4ynMFLSaNc2oJoChQyE52d56REREPJzCjB1GjYKoKDh8GJ580u5qREREPJrCjB18fODtt6FYMVi4EP79b7srEhER8VgKM3apVw9GjDD7jz8Ox47ZWo6IiIinUpix0/jxUL06HDxohmuLiIhIjinM2MnPD+bONftz58I339hbj4iIiAdSmLFb8+bmMRPAgAFw8qS99YiIiHgYhRl3EB0NERGwd+/FYdsiIiJyXRRm3EFgILzxhtl/9VXYuNHWckRERDyJwoy76NgRHn7YLHHQrx+kpdldkYiIiEdQmHEnr7wCwcGwc+fFRSlFRETkqhRm3EnZsjBzptmPjoYff7S3HhEREQ+gMONu7rsPunWDc+egb1/zVURERK5IYcbdOBwwaxaUKgVbtphHTyIiInJFCjPuKCwMpk83+889B7/8Ym89IiIibkxhxl316QNt28KZM2YyvYwMuysSERFxSwoz7srhgDffBH9/WLPm4jw0IiIikoXCjDurXNmMagIYORIOHLC3HhERETekMOPuBg+Gxo3hxAkYNMhMqiciIiIuCjPuzssL3noLfH3hq6/ggw/srkhERMStKMx4gltvNaOaAIYOhT/+sLceERERN6Iw4ylGjoQ6deDIEXjySburERERcRsKM57Cxwfefts8dvroI1iyxO6KRERE3ILCjCe54w54+mmz/9hjcPSovfWIiIi4AYUZT/Pcc1CjBiQlwYgRdlcjIiJiO4UZT+PnZ0Y3gXns9PXX9tYjIiJiM4UZT9SsmZl/BsxSBydP2luPiIiIjWwNM7NnzyYqKorAwEACAwNp3LgxX331let8nz59cDgcWbZGjRrZWLEbiY6GSpVg3z4YO9buakRERGxja5ipWLEiU6ZMYfPmzWzevJnWrVvTpUsXduzY4bqmQ4cOHDp0yLV9+eWXNlbsRgICzNpNAK+9Bhs22FuPiIiITWwNM507d+aee+6hRo0a1KhRg0mTJlGyZEk2btzousbpdBIaGuraypQpY2PFbubuu6F3b7PEQb9+kJZmd0UiIiIFzm36zJw/f56YmBhOnjxJ48aNXcdjY2MJDg6mRo0aDBgwgOTk5Ku+T1paGqmpqVm2Qm36dAgJgZ9+gokT7a5GRESkwNkeZhISEihZsiROp5NBgwaxePFiatasCUDHjh354IMPWLVqFdOmTWPTpk20bt2atKvcgYiOjiYoKMi1RUREFFRT7FGmDMyaZfanTIFt2+ytR0REpIA5LMveZZjT09M5cOAAx44d49NPP2Xu3LnExcW5Ak1mhw4dIjIykpiYGLp3737Z90tLS8sSdlJTU4mIiCAlJYXAwMB8a4ft7rsPPv3UzEGzebPpUyMiIuKhUlNTCQoKuq7f37bfmfH19aVatWrUr1+f6Oho6tSpw4wZMy57bVhYGJGRkezevfuK7+d0Ol2joy5sRcIbb0DFivDLL2Z2YHszqoiISIGxPcxcyrKsKz5GOnz4MImJiYSFhRVwVR6gbFn48EOzdtMHH8A779hdkYiISIGwNcyMGTOGtWvXsm/fPhISEhg7diyxsbH06tWLEydOMGLECDZs2MC+ffuIjY2lc+fOlCtXjm7dutlZtvtq1gwmTDD7gwfDzp321iMiIlIAvO388D/++IOHH36YQ4cOERQURFRUFMuWLaNdu3acPn2ahIQE3nvvPY4dO0ZYWBitWrVi4cKFBKg/yJU98wzExsLKldCjB3z/Pfj7212ViIhIvrG9A3B+y0kHokLjjz/g9tvNYpT9+8OcOXZXJCIikiMe1QFY8kFIiOk343DA3LmwYIHdFYmIiOQbhZnCqnVrePZZsz9wIFxlBJiIiIgnU5gpzJ57Dlq0gBMnTP+ZM2fsrkhERCTPKcwUZheGaZcrB/Hx8PTTdlckIiKS5xRmCrsKFeC998z+zJmwaJG99YiIiOQxhZmioGNHGDnS7PftC3v32luPiIhIHlKYKSomToRGjSAlBR54ANLT7a5IREQkTyjMFBU+PhATA6VKmYn0xoyxuyIREZE8oTBTlERGwrx5Zn/aNPj8c3vrERERyQMKM0VN167w5JNmv3dv+O03W8sRERG5UQozRdHUqXDHHXDkCDz4IJw7Z3dFIiIiuaYwUxQ5nbBwIQQEwLp1MH683RWJiIjkmsJMUVWtGrz5ptmfPNmssi0iIuKBFGaKsgcegEcfBcuChx4yq2yLiIh4GIWZou7VV6FWLUhOhl694Px5uysSERHJEYWZos7PDz76CPz9YdUqiI62uyIREZEcUZgRuPVW+Ne/zP64cbBmjb31iIiI5IDCjBi9e8Mjj0BGhhmu/eefdlckIiJyXRRm5KJZs+Dmm+HgQRNuMjLsrkhEROSaFGbkopIlTf8ZpxO++gqmT7e7IhERkWtSmJGsoqJgxgyzP3o0bNxobz0iIiLXoDAj2T36KPToYZY5eOABOHrU7opERESuSGFGsnM4YM4cqFoV9u+Hfv3MxHoiIiJuSGFGLi8w0Kzf5OMDixebzsEiIiJuSGFGrqxePXj5ZbP/97/D1q321iMiInIZCjNydUOGQJcukJ4O998Pqal2VyQiIpKFwoxcncMBb78NlSrBr7/CwIHqPyMiIm5FYUaurUwZiIkBLy/z9a237K5IRETERWFGrk/jxjB5stkfMgS2b7e3HhERkf9RmJHrN2IEdOgAZ86YeWhOnrS7IhEREYUZyYFixeC99yA8HH76ydyhERERsZnCjORM+fKwYIEJNvPmwfvv212RiIgUcQozknMtWsC4cWb/scfg55/trUdERIo0hRnJnbFjoVUr02+mSxc4csTuikREpIhSmJHc8fKCDz8088/88gvcd5+ZWE9ERKSA2RpmZs+eTVRUFIGBgQQGBtK4cWO++uor13nLshg/fjzh4eH4+fnRsmVLduzYYWPFkkVICHz2GZQsCatXw+OPa0I9EREpcLaGmYoVKzJlyhQ2b97M5s2bad26NV26dHEFlqlTpzJ9+nRmzpzJpk2bCA0NpV27dhw/ftzOsiWzqCgzkV6xYmYyvQtrOYmIiBQQh2W51z+ly5Qpw0svvUTfvn0JDw9n2LBhjBo1CoC0tDRCQkJ48cUXGThw4HW9X2pqKkFBQaSkpBAYGJifpRdtM2bAsGFm+YNFi6BrV7srEhERD5aT399u02fm/PnzxMTEcPLkSRo3bszevXtJSkqiffv2rmucTictWrRg/fr1NlYql/Xkk2Zkk2VBr15aYVtERAqM7WEmISGBkiVL4nQ6GTRoEIsXL6ZmzZokJSUBEBISkuX6kJAQ17nLSUtLIzU1NcsmBcDhgNdeg/bt4dQp6NwZfv/d7qpERKQIsD3M3HzzzcTHx7Nx40Yee+wxevfuzc6dO13nHQ5Hlusty8p2LLPo6GiCgoJcW0RERL7VLpfw9oaPPoKaNeHgQRNotOSBiIjkM9vDjK+vL9WqVaN+/fpER0dTp04dZsyYQWhoKEC2uzDJycnZ7tZkNnr0aFJSUlxbYmJivtYvlwgKgs8/NzMFb9sGDz0EGRl2VyUiIoWY7WHmUpZlkZaWRuXKlQkNDWXlypWuc+np6cTFxdGkSZMrfr/T6XQN9b6wSQGrXBmWLAGn03x95hm7KxIRkULM284PHzNmDB07diQiIoLjx48TExNDbGwsy5Ytw+FwMGzYMCZPnkz16tWpXr06kydPxt/fn549e9pZtlyPJk3g7bdNZ+CXXoIaNaB/f7urEhGRQsjWMPPHH3/w8MMPc+jQIYKCgoiKimLZsmW0a9cOgJEjR3L69Gkef/xxjh49SsOGDVmxYgUBAQF2li3Xq2dPMzvw88+bkU5VqkDr1nZXJSIihYzbzTOT1zTPjM0uDNX+8EMoVQo2boSbb7a7KhERcXMeOc+MFFIOh3nc1LgxHDsGnTrB4cN2VyUiIoWIwozkv+LFTUfgm26C//wHuneHtDS7qxIRkUJCYUYKRnCwWZQyIADWrIGBA7UopYiI5AmFGSk4tWqZSfWKFYN334UpU+yuSERECgGFGSlYHTqYZQ8AxoyBTz6xtx4REfF4CjNS8AYPhiFDzP4jj8CmTfbWIyIiHk1hRuwxfTp07AinT8Nf/gJadkJERHJJYUbs4e0NMTGmH01SklmU8sQJu6sSEREPpDAj9gkMNItShoTADz/Agw/C+fN2VyUiIh5GYUbsFRkJ//63mYvm88/h6aftrkhERDyMwozYr2FDM1Qb4JVX4I037K1HREQ8isKMuIcePeCFF8z+4MGwcqW99YiIiMdQmBH3MXYsPPyw6Tfzt7/BTz/ZXZGIiHgAhRlxHw4HzJkDTZtCSopZlPLPP+2uSkRE3JzCjLgXpxMWL4YqVWDvXujWTYtSiojIVSnMiPspX96MbAoKgm+/hf79tSiliIhckcKMuKdbbzXrNnl5wfz5MGmS3RWJiIibUpgR99W2LcyaZfaffdasuC0iInIJhRlxbwMHwlNPmf3eveG77+ytR0RE3E6ehZljx47l1VuJZPXSS2btpjNnzKKU+/fbXZGIiLiRXIWZF198kYULF7pe9+jRg7Jly1KhQgV++OGHPCtOBDD9ZhYsgDp1IDkZ7r0XUlPtrkpERNxErsLMG2+8QUREBAArV65k5cqVfPXVV3Ts2JGntbaO5IeSJeGzzyAsDLZvh7/+1dypERGRIi9XYebQoUOuMPP555/To0cP2rdvz8iRI9m0aVOeFijiEhEBS5dCiRLw9ddmluD0dLurEhERm+UqzJQuXZrExEQAli1bRtu2bQGwLIvz58/nXXUil6pf38xBc2GV7Z494dw5u6sSEREb5SrMdO/enZ49e9KuXTsOHz5Mx44dAYiPj6datWp5WqBINi1bwpIl4OsLn35qRjkpRIuIFFm5CjOvvPIKTzzxBDVr1mTlypWULFkSMI+fHn/88TwtUOSy7r7bTKrn7W06Bw8YABkZdlclIiI2cFhW4Z4nPjU1laCgIFJSUggMDLS7HMlrn3wC999vgsxjj5lJ9hwOu6sSEZEblJPf3965+YD33nvvqucfeeSR3LytSM7ddx+89x48/DDMnm0Wqpw+XYFGRKQIydWdmdKlS2d5ffbsWU6dOoWvry/+/v4cOXIkzwq8UbozU0S89ZZZkBLgmWdg8mQFGhERD5aT39+56jNz9OjRLNuJEyfYtWsXzZo148MPP8xV0SI3pF+/i+s4TZkCL7xgbz0iIlJg8mw5g+rVqzNlyhSGDh2aV28pkjOPPw7Tppn9ceNg6lR76xERkQKRpwtNenl5cfDgwbx8S5GcGT4cJk0y+6NGwWuv2VuPiIjku1x1AF66dGmW15ZlcejQIWbOnEnTpk3zpDCRXBszBk6fhokTYehQM8Heo4/aXZWIiOSTXIWZrl27ZnntcDgoX748rVu3ZtqF2/widpowwazd9PLLMGiQGeXUu7fdVYmISD7IVZjJ0ORk4u4cDtNn5swZmDkT+vY1d2juv9/uykREJI/laZ8ZEbficMCMGWbIdkYG9OoFixfbXZWIiOSxXIWZ8+fP89Zbb9GzZ0/atm1L69ats2zXKzo6mjvvvJOAgACCg4Pp2rUru3btynJNnz59cDgcWbZGjRrlpmwpiooVg9dfN5PqnT9v7sx8+aXdVYmISB7K1WOmoUOH8s4779CpUydq1aqFI5eTk8XFxTF48GDuvPNOzp07x9ixY2nfvj07d+6kRIkSrus6dOjAvHnzXK99fX1z9XlSRHl5wdtvm0dOH38M3bubFbf/t9q7iIh4tlyFmZiYGD766CPuueeeG/rwZcuWZXk9b948goOD2bJlC82bN3cddzqdhIaG3tBnSRHn7Q0ffADp6fDvf8Nf/gLLlkGm/85ERMQz5eoxk6+vL9WqVcvrWkhJSQGgTJkyWY7HxsYSHBxMjRo1GDBgAMnJyXn+2VIE+PjAwoXQoYMZut2pE2zcaHdVIiJyg3K1NtO0adPYs2cPM2fOzPUjpktZlkWXLl04evQoa9eudR1fuHAhJUuWJDIykr179/Lss89y7tw5tmzZgtPpzPY+aWlppKWluV6npqYSERGhtZnkotOn4d57YdUqCAoyX++4w+6qREQkk5yszZSrMNOtWzdWr15NmTJluO222/Dx8clyftGiRTl9SwYPHswXX3zBunXrqFix4hWvO3ToEJGRkcTExNC9e/ds58ePH8/zzz+f7bjCjGRx8qS5Q7NuHZQpA7GxULu23VWJiMj/5PtCk6VKlaJbt260aNGCcuXKERQUlGXLqSFDhrB06VJWr1591SADEBYWRmRkJLt3777s+dGjR5OSkuLaEhMTc1yPFAElSsAXX0CDBnDkCLRpAz//bHdVIiKSC7nqAJx5ZNGNsCyLIUOGsHjxYmJjY6lcufI1v+fw4cMkJiYSFhZ22fNOp/Oyj59EsgkMNJ2AW7eG+Hjzdc0ayIf+YCIikn9uaNK8P//8k3Xr1vHtt9/y559/5vj7Bw8ezPz581mwYAEBAQEkJSWRlJTE6dOnAThx4gQjRoxgw4YN7Nu3j9jYWDp37ky5cuXo1q3bjZQuYpQuDStXwm23waFD5g7N/v12VyUiIjmQqzBz8uRJ+vbtS1hYGM2bN+euu+4iPDycfv36cerUqet+n9mzZ5OSkkLLli0JCwtzbQsXLgTMKtwJCQl06dKFGjVq0Lt3b2rUqMGGDRsICAjITeki2ZUrB998AzVqwIED5g7N77/bXZWIiFynXHUAHjhwIF9//XWWVbLXrVvHk08+Sbt27Zg9e3aeF5pbOelAJEXc77+beWf27DHBJi4ONL+RiIgt8n00U7ly5fjkk09o2bJlluOrV6+mR48euXrklF8UZiRH9u+Hu+6CxETz6Ck21ty5ERGRApXvo5lOnTpFSEhItuPBwcE5eswk4nYiI828M2FhsGMHtGsHR4/aXZWIiFxFrsJM48aNGTduHGfOnHEdO336NM8//zyNGzfOs+JEbFGtmgk0wcFmlFOHDpCaandVIiJyBbl6zLR9+3Y6dOjAmTNnqFOnDg6Hg/j4eJxOJytWrOC2227Lj1pzRY+ZJNcSEqBlSzMPTdOmZhh3yZJ2VyUiUiTke58ZMHdi5s+fz88//4xlWdSsWZNevXrh5+eXq6Lzi8KM3JAtW8xw7ZQUaNECli4189OIiEi+yvc+M4cPH8bPz48BAwYwdOhQSpYsya5du9i8eXOuChZxW/XqXbwjExdnAk1Skt1ViYhIJjkKMwkJCdx0000EBwdzyy23EB8fT4MGDXjllVd48803adWqFUuWLMmnUkVs0qiRGdVUvrzpQ9O0Kfz6q91ViYjI/+QozIwcOZLatWsTFxdHy5Ytuffee7nnnntISUnh6NGjDBw4kClTpuRXrSL2qVcPvv0WKlc289A0bQpbt9pdlYiIkMM+M+XKlWPVqlVERUVx4sQJAgMD+f7776lfvz4AP//8M40aNeLYsWP5VW+Oqc+M5KmkJDO66YcfzKOnxYuhbVu7qxIRKXTyrc/MkSNHCP3fjKglS5akRIkSlClTxnW+dOnSHD9+PBcli3iI0FDTd6ZlSzhxAu65B/63/IaIiNgjxx2AHQ7HVV+LFHpBQaZT8H33wdmz8OCD8M9/2l2ViEiR5Z3Tb+jTpw9OpxOAM2fOMGjQIEqUKAFAWlpa3lYn4q6cToiJgaFDYdYsePJJ8whq4kRQwBcRKVA56jPzf//3f9d13bx583JdUF5TnxnJV5YFkybBs8+a1337whtvgHeO/50gIiKZFMikeZ5CYUYKxJw5MGgQZGRA587mro2/v91ViYh4rHyfNE9ELjFgAHz6KRQvDp99Bu3bm2UQREQk3ynMiOSVrl1hxQrTQfjbb+Guu+C33+yuSkSk0FOYEclLd90Fa9dCeDjs3AlNmsBPP9ldlYhIoaYwI5LXateG9evh5pshMRGaNYMNG+yuSkSk0FKYEckPkZGwbh00aGD6zrRpA198YXdVIiKFksKMSH4pVw5WrTLLH5w+DV26wLvv2l2ViEihozAjkp9KlIClS+Hhh+H8eejTB6ZONfPTiIhInlCYEclvPj7wzjvw9NPm9ahRMHy4mZNGRERumMKMSEEoVszckXn5ZfP61VfN3Zr0dFvLEhEpDBRmRArS3/8O779vljtYsMDMFqyV5kVEbojCjEhBe+ghM0twiRJmkr3WrSE52e6qREQ8lsKMiB06dDAjncqWhc2bzVw0e/faXZWIiEdSmBGxS4MGZtmDyEjYvdvMFvzDD3ZXJSLicRRmROx0881mtuDatSEpCZo3h9hYu6sSEfEoCjMidgsPhzVrTJBJTYW77zYrcIuIyHVRmBFxB6VKwfLl0K2bGa79t7/B66/bXZWIiEdQmBFxF8WLw8cfw6OPmhmCH3sMxo3TbMEiItegMCPiTry8zB2ZcePM6wkT4L77NBeNiMhVKMyIuBuHA8aPhzlzzFIIixZBw4awa5fdlYmIuCWFGRF31b+/6RgcHg4//WSGci9dandVIiJuR2FGxJ01agRbtphJ9VJToUsX8whKi1SKiLgozIi4u9BQ+OYbeOIJ83rCBPjLX+DYMVvLEhFxF7aGmejoaO68804CAgIIDg6ma9eu7LqkX4BlWYwfP57w8HD8/Pxo2bIlO3bssKliEZv4+sI//wnvvmtGPX3xBdx5J2zfbndlIiK2szXMxMXFMXjwYDZu3MjKlSs5d+4c7du35+TJk65rpk6dyvTp05k5cyabNm0iNDSUdu3acVyjO6QoeuQRswRCpUrw66/mMdTHH9tdlYiIrRyW5T6TWPz5558EBwcTFxdH8+bNsSyL8PBwhg0bxqhRowBIS0sjJCSEF198kYEDB17zPVNTUwkKCiIlJYXAwMD8boJIwfjvf+GBB8zjJ4CRI2HSJPD2trcuEZE8kpPf327VZyYlJQWAMmXKALB3716SkpJo37696xqn00mLFi1Yv379Zd8jLS2N1NTULJtIoVOuHCxbBk8/bV5PnQodO8Lhw/bWJSJiA7cJM5ZlMXz4cJo1a0atWrUASEpKAiAkJCTLtSEhIa5zl4qOjiYoKMi1RURE5G/hInbx9jYhZuFC8PeHr7+GevVg2za7KxMRKVBuE2aeeOIJfvzxRz788MNs5xwOR5bXlmVlO3bB6NGjSUlJcW2JiYn5Uq+I2+jRA777DqpWhf37oUkTeP99u6sSESkwbhFmhgwZwtKlS1m9ejUVK1Z0HQ8NDQXIdhcmOTk5292aC5xOJ4GBgVk2kUKvVi3YtAnuuQfOnDEdhYcOhbNn7a5MRCTf2RpmLMviiSeeYNGiRaxatYrKlStnOV+5cmVCQ0NZuXKl61h6ejpxcXE0adKkoMsVcW+lS8Nnn8Gzz5rXr70GbdvCH3/YW5eISD6zNcwMHjyY+fPns2DBAgICAkhKSiIpKYnTp08D5vHSsGHDmDx5MosXL2b79u306dMHf39/evbsaWfpIu6pWDEzqd6SJRAQYJZDqFfPPIYSESmkbB2afaV+L/PmzaNPnz6AuXvz/PPP88Ybb3D06FEaNmzIrFmzXJ2Er0VDs6XI2rULunaFn382k+7NnAkDBthdlYjIdcnJ72+3mmcmPyjMSJF2/Dj06WNW3gZ49FHz+MnptLUsEZFr8dh5ZkQkjwUEwCefwOTJ4HDAm29Cy5bw++92VyYikmcUZkQKO4cDRo+GL780nYQ3bjT9aNautbsyEZE8oTAjUlR06ACbN0NUlBnh1Lq1WbyycD9pFpEiQGFGpCipUgXWr4cHH4Rz5+DJJ6F3b/jfCEIREU+kMCNS1JQoAR98ANOng5eXmS24aVPYt8/uykREckVhRqQocjjgqadg5UooX96s51S/vlnfSUTEwyjMiBRlrVrBli0myBw+DHffDS+9pH40IuJRFGZEirqICDOy6f/+DzIyYORI01n44EG7KxMRuS4KMyICxYvDW2/B66+b/RUrzOKVH39sd2UiItekMCMihsMBAwea/jP16sHRo9CjBzz0EBw7Znd1IiJXpDAjIlndcgts2GBW3y5WzIx8ql0bVq2yuzIRkctSmBGR7Hx8zOrb334L1arBb79BmzYwfDicOWN3dSIiWSjMiMiVNWpkHjsNHGhev/KKGfm0bZu9dYmIZKIwIyJXV7Kk6Rj8+ecQEgI7dkDDhjBlCpw/b3d1IiIKMyJynTp1goQE6NYNzp41i1e2aAF79thdmYgUcQozInL9ypeHTz+Fd96BgADTp6ZOHTOsWxPtiYhNFGZEJGccDrM45Y8/wl13wYkT0L+/uWOTnGx3dSJSBCnMiEju3HQTrF4NU6ea0U///rcZwv3ZZ3ZXJiJFjMKMiOSelxc8/TRs2mSCTHIy/OUvMGAAHD9ud3UiUkQozIjIjatTB77/HkaMMI+h5s6F22+H9evtrkxEigCFGRHJG8WLmxW3V62CSpXMKKe77oKxYyE93e7qRKQQU5gRkbzVsqXpHPzII2YV7smTzeR7O3faXZmIFFIKMyKS94KC4N134ZNPoGxZM2PwHXfAjBkm4IiI5CGFGRHJP3/9q5lor2NHSEuDYcOgfXuz1pOISB5RmBGR/BUWBl98AbNng78/fPONGfn04Yd2VyYihYTCjIjkP4cDBg0yj5saNIBjx6BnT3jwQThyxO7qRMTDKcyISMGpUcMsgfD882aOmpgYiIqClSvtrkxEPJjCjIgULG9veO452LDBhJvffzf9aPr1g//+1+7qRMQDKcyIiD3uvNM8dho82Lx++224+WaYM0cjnkQkRxRmRMQ+/v4wc6Z59BQVZfrPPPooNGligo6IyHVQmBER+zVpAlu2wCuvQMmS8N13UL8+DB0KKSl2Vycibk5hRkTcg7e3mYdm1y544AHzqOm11+CWW8wwbsuyu0IRcVMKMyLiXsLDTXhZudJ0EE5KMsO427aFn3+2uzoRcUMKMyLintq2NWs8TZxoFrFctcr0qxkzBk6dsrs6EXEjCjMi4r6cTrPq9s6d0KkTnD0L0dFQsyYsXWp3dSLiJhRmRMT9Va4Mn30GS5ZApUqwfz906QJ/+Qvs3Wt3dSJiM1vDzJo1a+jcuTPh4eE4HA6WLFmS5XyfPn1wOBxZtkaNGtlTrIjYy+EwAWbnTnjmGfDxMQHntttg8mSzkKWIFEm2hpmTJ09Sp04dZs6cecVrOnTowKFDh1zbl19+WYAViojbKVHCPGr64Qdo1QpOnzaPourUMYtYikiR423nh3fs2JGOHTte9Rqn00loaGgBVSQiHuPWW014+fBDGD7cDOlu29YM6542zYyKEpEiwe37zMTGxhIcHEyNGjUYMGAAycnJV70+LS2N1NTULJuIFFIOhxm2vWsXDBkCxYqZxStvuQVmzIBz5+yuUEQKgFuHmY4dO/LBBx+watUqpk2bxqZNm2jdujVpV3k2Hh0dTVBQkGuLiIgowIpFxBZBQWaCvU2boEEDOH7cTMBXv75Z0FJECjWHZbnHtJoOh4PFixfTtWvXK15z6NAhIiMjiYmJoXv37pe9Ji0tLUvYSU1NJSIigpSUFAIDA/O6bBFxNxkZMHeu6SR89Kg51r8/TJkCZcvaW5uIXLfU1FSCgoKu6/e3W9+ZuVRYWBiRkZHs3r37itc4nU4CAwOzbCJShBQrZhar3LUL+vY1x+bONStyz52rFblFCiGPCjOHDx8mMTGRsLAwu0sREXdXvjy89RasWwe1a8PhwzBgADRtCvHxdlcnInnI1jBz4sQJ4uPjif/f/1j27t1LfHw8Bw4c4MSJE4wYMYINGzawb98+YmNj6dy5M+XKlaNbt252li0inqRpU9i6FaZPNytyb9wI9eqZPjVakVukULA1zGzevJm6detSt25dAIYPH07dunV57rnn8PLyIiEhgS5dulCjRg169+5NjRo12LBhAwEBAXaWLSKextsbnnrKLFTZo4d51DRjBlSpYoZxnzljd4UicgPcpgNwfslJByIRKSJWrDB3Zn76ybyuWBGefx4eecQEHxGxXaHtACwikifatzcrcr/9NkREwG+/Qb9+ZlXuxYuhcP8bT6TQUZgRkaLJ2xv+7//gl1/Mo6YyZcydmu7doXFjiI21u0IRuU4KMyJStBUvbpZD2LPHrPHk7w/ffWfWferYEbZts7tCEbkGhRkRETCzCE+cCP/5Dzz+uLlzs2wZ3HGHWTLhP/+xu0IRuQKFGRGRzEJDYdYsM/LpwQfNsQ8/NOs9DR4MSUn21ici2SjMiIhcTtWqsGCBeczUoYNZtPJf/zLHn31Wc9SIuBGFGRGRq7n9dvjqK1i9Gho2hFOnzOOoqlXNRHyao0bEdgozIiLXo2VLswL34sVw661meYS//x1q1IB588ydGxGxhcKMiMj1cjiga9esc9QkJpoFLaOiYMkSzVEjYgOFGRGRnLrSHDXdukGTJhAXZ3eFIkWKwoyISG5dbo6ajRvNI6mOHbU6t0gBUZgREblRV5qjpm5dzVEjUgAUZkRE8srV5qh54gnNUSOSTxRmRETy2uXmqJk1yxx/5hmFGpE8pjAjIpJfLjdHzYsvwk03waBB8OuvdlcoUigozIiI5LcLc9QsXWpW5E5LgzfegJtvhvvvh61b7a5QxKMpzIiIFASHAzp3hm+/hTVroFMnyMiAjz6CevWgfXtYtUrz1IjkgsKMiEhBcjjgrrvg88/hhx+gVy/w8oKVK6FNG2jQAD79FM6ft7tSEY+hMCMiYpeoKJg/3/SdeeIJ8PODzZvhvvugZk2YO9c8khKRq1KYERGx2003wT//Cfv3mxW5S5c2swsPGACVK8NLL0Fqqt1VirgthRkREXdRvjxMmAAHDpgVuStUgEOHYORIqFTJzDL8xx92VynidhRmRETcTcmS8NRTZpmEt982k+6lpMDkyRAZaWYZ3rPH7ipF3IbCjIiIu/L1NQta7tgBixebuWrS0mD2bKhe3cwyrPWfRBRmRETcXrFi0LWrmasmNtbMKpyRATExZv2nDh3McQ3rliJKYUZExFM4HNCihZlVeNs2c2emWDFYvhxatYJGjcwdnIwMuysVKVAKMyIinuj22836T7t3mz40xYvD999D9+5mWPfbb0N6ut1VihQIhRkREU9WpYpZxHLfPhgzBoKCYNcu6NfPnJs2DY4ft7tKkXylMCMiUhiEhMCkSWZY90svQVgY/P47jBgBFSuaSfl27LC7SpF8oTAjIlKYBAaaALN3r5lBuEYNM+HerFlQqxY0b24eT2lmYSlEFGZERAojp9M8avrpJ1ixwvSl8fKCtWvNelAREfDMMyb0iHg4hRkRkcKsWDFo184sXrl/P4wfb2YW/vNPePFFqFoV7rkHli7V4pbisRRmRESKigoVYNw401l48WJo397MTfPVV9Cli1kHauJESEqyu1KRHFGYEREpary9zSR8y5ebod0jRkDZspCYaBa6jIiAv/0NVq3SRHziERRmRESKsmrVzOin336D99+HJk3g3Dn45BNo0wZuvRVefRWOHrW7UpErUpgREREz6d5DD8G338IPP8CgQWbBy127zKKX4eFmnajvv9fdGnE7CjMiIpJVVJRZzPLgQfM1KgrOnIF33jGLXdavb4Z9nzxpd6UigM1hZs2aNXTu3Jnw8HAcDgdLlizJct6yLMaPH094eDh+fn60bNmSHZr0SUSkYAQEmDs08fHmjs1DD5kh31u3woABpkPxk0/Czp12VypFnK1h5uTJk9SpU4eZM2de9vzUqVOZPn06M2fOZNOmTYSGhtKuXTuOa2puEZGC43CYvjTvv2/61rz0khnSnZIC//wn3HabWQAzJkbrQYktHJblHg8/HQ4HixcvpmvXroC5KxMeHs6wYcMYNWoUAGlpaYSEhPDiiy8ycODA63rf1NRUgoKCSElJITAwML/KFxEpWjIy4Ouv4fXXs85RExwMffvCo4+aod4iuZST399u22dm7969JCUl0b59e9cxp9NJixYtWL9+/RW/Ly0tjdTU1CybiIjksWLFzDw1ixaZeWvGjTOdhJOTYcoUs8hl8+bw5psaCSX5zm3DTNL/Jm0KCQnJcjwkJMR17nKio6MJCgpybREREflap4hIkVexoplZeN8+M9Nwu3bm0dTatTBwIISGmuUUFi3SmlCSL9w2zFzgcDiyvLYsK9uxzEaPHk1KSoprS0xMzO8SRUQEwMfHhJYVK8zq3VOnmpFQ6elmxuG//tUEm0cfhbg486hKJA+4bZgJDQ0FyHYXJjk5OdvdmsycTieBgYFZNhERKWAVK8LTT5s5a374AUaONMeOHYM5c6BlS7jpJhg9GjRKVW6Q24aZypUrExoaysqVK13H0tPTiYuLo0mTJjZWJiIiORIVZRa13L8fVq82q3kHBprlE6ZMgVq1oG5dmDbNzG0jkkO2hpkTJ04QHx9PfHw8YDr9xsfHc+DAARwOB8OGDWPy5MksXryY7du306dPH/z9/enZs6edZYuISG4UK2buyMydC3/8AR9/bBa49PExc9mMGGHu3rRtaybo0wAOuU62Ds2OjY2lVatW2Y737t2bd955B8uyeP7553njjTc4evQoDRs2ZNasWdSqVeu6P0NDs0VE3NyRIybYzJ8P69ZdPF68uAk7vXrB3XeDr699NUqBy8nvb7eZZya/KMyIiHiQvXthwQITbH7++eLxsmXh/vvNLMSNGpnRUlKoKcxkojAjIuKBLAu2bTOh5sMPIfNgkCpVTKjp1Qtq1LCvRslXCjOZKMyIiHi4c+dg1Sr44AMzj03mBS7vvNMEm/vvh6uMdBXPozCTicKMiEghcvKkWT5h/nxYvvziMgpeXmayvr/+FTp3VrApBBRmMlGYEREppJKT4aOPTLD57ruLxx0OaNoUunY1W9WqdlUoN0BhJhOFGRGRImD3bjMiavFi2Lw567natS8Gm7p11XnYQyjMZKIwIyJSxCQmmkdRixdDbOzFR1EAlSqZUNOtGzRrBt7edlUp16Awk4nCjIhIEXbkCHzxBSxZAsuWwalTF8+VKWP613TrZvrb+PvbVqZkpzCTicKMiIgAcPo0rFxpgs3SpXD48MVzfn7QoYO5a3PvvSboiK0UZjJRmBERkWzOnYNvvzWPopYsMetGXeDlBS1aXOxnExFhU5FFm8JMJgozIiJyVZZl1oZassSEm4SErOfr1bvYz6ZmTXUgLiAKM5kozIiISI785z/w73+bYPPttybsXFCtmgk1XbuaZRWK2bpec6GmMJOJwoyIiORacrLpX7Nkielvk55+8VxIiFkIs2NHaN0a9DsmTynMZKIwIyIieeL4cTMiaskS+PxzSE29eM7LCxo3Nqt7t29vHk15edlWamGgMJOJwoyIiOS59HQzh83SpbBihZm0L7MyZaBtWxNs2rdXJ+JcUJjJRGFGRETy3d69JtQsXw7ffJP1rg3ArbdevGvTooXmtLkOCjOZKMyIiEiBOnfOrBW1YoXZvv8eMjIunvf1hbvuuhhuoqI0QuoyFGYyUZgRERFbHTkCq1aZuzbLl5vlFjILCbn4OKpdO634/T8KM5kozIiIiNuwLNi16+IjqdjYrEssANx++8W7Nk2bgtNpR6W2U5jJRGFGRETcVlqamcvmwiOpbduynvf3h5YtTbC5+264+eYi80hKYSYThRkREfEYf/wBX39t7tqsWGFeZ1apkgk2rVpB8+ZQsaI9dRYAhZlMFGZERMQjWRb8+OPFR1Jr12adtA+gcmUTau66y3ytVq3Q3LlRmMlEYUZERAqFU6dgzRoTbtasMY+kMo+SAggNvRhsmjeHWrU8dskFhZlMFGZERKRQSk2FDRtMsFmzxgwBv/TOTalS0KzZxXBzxx3g42NLuTmlMJOJwoyIiBQJZ86YQHMh3KxfDydPZr3G398su3Ah3DRsCH5+9tR7DQozmSjMiIhIkXT2LMTHXww369aZOW8y8/GBO++8GG6aNIGgIFvKvZTCTCYKMyIiIpj+NTt3Xgw3a9bAoUNZrylWDOrUudip+K67IDjYlnIVZjJRmBEREbkMy4I9ey4Gm7Vr4T//yX7dLbeYUNO0KTRoYOa6KYBOxQozmSjMiIiIXKfffzehZu1aE3C2b89+TWAg1K9v+ts0aGC28PA8L0VhJhOFGRERkVw6fNjMULxmjVk8c8sWOH06+3UVKlwMNg0amLBzg79zFWYyUZgRERHJI+fOwY4dZtTUhW379uzz3Tgc5vFU5oATFWVWDL9OCjOZKMyIiIjko5MnYetWE2y++8583b8/+3VOJ9StmzXgXGXGYoWZTBRmRERECtgff8CmTVnv4Bw9mv260qXN0PDMASckBFCYyUJhRkRExGaWZUZKZQ43W7eaVcMvVakSNGhAalQUQc89pzADkJKSQqlSpUhMTFSYERERcRfp6Wbemy1bLm4//+w6nQpEAMeOHSPoGhP5eedvpfY7fvw4ABERETZXIiIiIjl1/Pjxa4aZQn9nJiMjg4MHDxIQEICjAJZFT01NJSIiolDeCVLbPJPa5pnUNs+ktuUdy7I4fvw44eHhFLvGJH2F/s5MsWLFqFixYoF/bmBgYKH7D/kCtc0zqW2eSW3zTGpb3rjWHZkL8n8+YhEREZF8pDAjIiIiHk1hJo85nU7GjRuH0+m0u5Q8p7Z5JrXNM6ltnklts0eh7wAsIiIihZvuzIiIiIhHU5gRERERj6YwIyIiIh5NYUZEREQ8msJMLqxZs4bOnTsTHh6Ow+FgyZIlWc5blsX48eMJDw/Hz8+Pli1bsmPHDnuKzaHo6GjuvPNOAgICCA4OpmvXruzatSvLNZ7avtmzZxMVFeWa8Klx48Z89dVXrvOe2q7LiY6OxuFwMGzYMNcxT23f+PHjcTgcWbbQ0FDXeU9t1wW///47Dz30EGXLlsXf35/bb7+dLVu2uM57cvtuuummbD87h8PB4MGDAc9t27lz5/jHP/5B5cqV8fPzo0qVKkyYMIGMjAzXNZ7aNjDLBwwbNozIyEj8/Pxo0qQJmzZtcp13y7ZZkmNffvmlNXbsWOvTTz+1AGvx4sVZzk+ZMsUKCAiwPv30UyshIcG6//77rbCwMCs1NdWegnPg7rvvtubNm2dt377dio+Ptzp16mRVqlTJOnHihOsaT23f0qVLrS+++MLatWuXtWvXLmvMmDGWj4+PtX37dsuyPLddl/r++++tm266yYqKirKGDh3qOu6p7Rs3bpx12223WYcOHXJtycnJrvOe2i7LsqwjR45YkZGRVp8+fazvvvvO2rt3r/X1119bv/76q+saT25fcnJylp/bypUrLcBavXq1ZVme27aJEydaZcuWtT7//HNr79691scff2yVLFnSevXVV13XeGrbLMuyevToYdWsWdOKi4uzdu/ebY0bN84KDAy0fvvtN8uy3LNtCjM36NIwk5GRYYWGhlpTpkxxHTtz5owVFBRkvf766zZUeGOSk5MtwIqLi7Msq/C1r3Tp0tbcuXMLTbuOHz9uVa9e3Vq5cqXVokULV5jx5PaNGzfOqlOnzmXPeXK7LMuyRo0aZTVr1uyK5z29fZcaOnSoVbVqVSsjI8Oj29apUyerb9++WY51797deuihhyzL8uyf26lTpywvLy/r888/z3K8Tp061tixY922bXrMlMf27t1LUlIS7du3dx1zOp20aNGC9evX21hZ7qSkpABQpkwZoPC07/z588TExHDy5EkaN25caNo1ePBgOnXqRNu2bbMc9/T27d69m/DwcCpXrswDDzzAnj17AM9v19KlS6lfvz5/+9vfCA4Opm7dusyZM8d13tPbl1l6ejrz58+nb9++OBwOj25bs2bN+Oabb/jll18A+OGHH1i3bh333HMP4Nk/t3PnznH+/HmKFy+e5bifnx/r1q1z27YpzOSxpKQkAEJCQrIcDwkJcZ3zFJZlMXz4cJo1a0atWrUAz29fQkICJUuWxOl0MmjQIBYvXkzNmjU9vl0AMTExbN26lejo6GznPLl9DRs25L333mP58uXMmTOHpKQkmjRpwuHDhz26XQB79uxh9uzZVK9eneXLlzNo0CCefPJJ3nvvPcCzf26XWrJkCceOHaNPnz6AZ7dt1KhRPPjgg9xyyy34+PhQt25dhg0bxoMPPgh4dtsCAgJo3LgxL7zwAgcPHuT8+fPMnz+f7777jkOHDrlt2wr9qtl2cTgcWV5blpXtmLt74okn+PHHH1m3bl22c57avptvvpn4+HiOHTvGp59+Su/evYmLi3Od99R2JSYmMnToUFasWJHtX1SZeWL7Onbs6NqvXbs2jRs3pmrVqrz77rs0atQI8Mx2AWRkZFC/fn0mT54MQN26ddmxYwezZ8/mkUcecV3nqe3L7K233qJjx46Eh4dnOe6JbVu4cCHz589nwYIF3HbbbcTHxzNs2DDCw8Pp3bu36zpPbBvA+++/T9++falQoQJeXl7ccccd9OzZk61bt7qucbe26c5MHrswyuLShJqcnJwtybqzIUOGsHTpUlavXk3FihVdxz29fb6+vlSrVo369esTHR1NnTp1mDFjhse3a8uWLSQnJ1OvXj28vb3x9vYmLi6O1157DW9vb1cbPLV9mZUoUYLatWuze/duj/+5hYWFUbNmzSzHbr31Vg4cOAB4/t+3C/bv38/XX39N//79Xcc8uW1PP/00zzzzDA888AC1a9fm4Ycf5qmnnnLdFfXktgFUrVqVuLg4Tpw4QWJiIt9//z1nz56lcuXKbts2hZk8duGHvXLlStex9PR04uLiaNKkiY2VXR/LsnjiiSdYtGgRq1atonLlylnOe3r7LmVZFmlpaR7frjZt2pCQkEB8fLxrq1+/Pr169SI+Pp4qVap4dPsyS0tL46effiIsLMzjf25NmzbNNvXBL7/8QmRkJFB4/r7NmzeP4OBgOnXq5DrmyW07deoUxYpl/fXp5eXlGprtyW3LrESJEoSFhXH06FGWL19Oly5d3Ldt9vQ79mzHjx+3tm3bZm3bts0CrOnTp1vbtm2z9u/fb1mWGbYWFBRkLVq0yEpISLAefPBB24etXa/HHnvMCgoKsmJjY7MMqTx16pTrGk9t3+jRo601a9ZYe/futX788UdrzJgxVrFixawVK1ZYluW57bqSzKOZLMtz2/f3v//dio2Ntfbs2WNt3LjRuvfee62AgABr3759lmV5brssywyj9/b2tiZNmmTt3r3b+uCDDyx/f39r/vz5rms8uX2WZVnnz5+3KlWqZI0aNSrbOU9tW+/eva0KFSq4hmYvWrTIKleunDVy5EjXNZ7aNsuyrGXLlllfffWVtWfPHmvFihVWnTp1rAYNGljp6emWZbln2xRmcmH16tUWkG3r3bu3ZVlmWN64ceOs0NBQy+l0Ws2bN7cSEhLsLfo6Xa5dgDVv3jzXNZ7avr59+1qRkZGWr6+vVb58eatNmzauIGNZntuuK7k0zHhq+y7MYeHj42OFh4db3bt3t3bs2OE676ntuuCzzz6zatWqZTmdTuuWW26x3nzzzSznPb19y5cvtwBr165d2c55attSU1OtoUOHWpUqVbKKFy9uValSxRo7dqyVlpbmusZT22ZZlrVw4UKrSpUqlq+vrxUaGmoNHjzYOnbsmOu8O7bNYVmWZcstIREREZE8oD4zIiIi4tEUZkRERMSjKcyIiIiIR1OYEREREY+mMCMiIiIeTWFGREREPJrCjIiIiHg0hRkREeCdd96hVKlSrtfjx4/n9ttvt60eEbl+CjMikmt9+vTB4XDgcDjw8fGhSpUqjBgxgpMnT9pd2lXddNNNvPrqq1mO3X///fzyyy/2FCQiN8Tb7gJExLN16NCBefPmcfbsWdauXUv//v05efIks2fPztH7WJbF+fPn8fa2539Lfn5++Pn52fLZInJjdGdGRG6I0+kkNDSUiIgIevbsSa9evViyZAmWZTF16lSqVKmCn58fderU4ZNPPnF9X2xsLA6Hg+XLl1O/fn2cTidr164lIyODF198kWrVquF0OqlUqRKTJk1yfd/vv//O/fffT+nSpSlbtixdunRh3759rvN9+vSha9euvPzyy4SFhVG2bFkGDx7M2bNnAWjZsiX79+/nqaeect1VguyPmS5n3rx53HrrrRQvXpxbbrmFf/3rX3n3BykiuaY7MyKSp/z8/Dh79iz/+Mc/WLRoEbNnz6Z69eqsWbOGhx56iPLly9OiRQvX9SNHjuTll1+mSpUqlCpVitGjRzNnzhxeeeUVmjVrxqFDh/j5558BOHXqFK1ateKuu+5izZo1eHt7M3HiRDp06MCPP/6Ir68vAKtXryYsLIzVq1fz66+/cv/993P77bczYMAAFi1aRJ06dXj00UcZMGDAdbdrzpw5jBs3jpkzZ1K3bl22bdvGgAEDKFGiBL17987bP0QRyRGFGRHJM99//z0LFiygVatWTJ8+nVWrVtG4cWMAqlSpwrp163jjjTeyhJkJEybQrl07AI4fP86MGTOYOXOmKyBUrVqVZs2aARATE0OxYsWYO3eu647KvHnzKFWqFLGxsbRv3x6A0qVLM3PmTLy8vLjlllvo1KkT33zzDQMGDKBMmTJ4eXkREBBAaGjodbfthRdeYNq0aXTv3h2AypUrs3PnTt544w2FGRGbKcyIyA35/PPPKVmyJOfOnePs2bN06dKFESNG8Mknn7hCygXp6enUrVs3y7H69eu79n/66SfS0tJo06bNZT9ry5Yt/PrrrwQEBGQ5fubMGf7zn/+4Xt922214eXm5XoeFhZGQkJDrNv75558kJibSr1+/LHdzzp07R1BQUK7fV0TyhsKMiNyQVq1aMXv2bHx8fAgPD8fHx4fvvvsOgC+++IIKFSpkud7pdGZ5XaJECdf+tTrgZmRkUK9ePT744INs58qXL+/a9/HxyXLO4XCQkZFxfQ26wueCedTUsGHDLOcyhyYRsYfCjIjckBIlSlCtWrUsx2rWrInT6eTAgQNZHildS/Xq1fHz8+Obb76hf//+2c7fcccdLFy4kODgYAIDA3Nds6+vL+fPn7/u60NCQqhQoQJ79uyhV69euf5cEckfCjMikucCAgIYMWIETz31FBkZGTRr1ozU1FTWr19PyZIlr9jHpHjx4owaNYqRI0fi6+tL06ZN+fPPP9mxYwf9+vWjV69evPTSS3Tp0oUJEyZQsWJFDhw4wKJFi3j66aepWLHiddV30003sWbNGh544AGcTiflypW75veMHz+eJ598ksDAQDp27EhaWhqbN2/m6NGjDB8+PEd/PiKStxRmRCRfvPDCCwQHBxMdHc2ePXsoVaoUd9xxB2PGjLnq9z377LN4e3vz3HPPcfDgQcLCwhg0aBAA/v7+rFmzhlGjRtG9e3eOHz9OhQoVaNOmTY7u1EyYMIGBAwdStWpV0tLSsCzrmt/Tv39//P39eemllxg5ciQlSpSgdu3aDBs27Lo/V0Tyh8O6nr/FIiIiIm5Kk+aJiIiIR1OYEREREY+mMCMiIiIeTWFGREREPJrCjIiIiHg0hRkRERHxaAozIiIi4tEUZkRERMSjKcyIiIiIR1OYEREREY+mMCMiIiIeTWFGREREPNr/AyiV0fRwg0HFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is just to show you the bonus curve. This is NOT part of the question.\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = 50\n",
    "b = 0.025\n",
    "c = 1 \n",
    "x = np.linspace(5, 95, 18, endpoint = True)\n",
    "y = (a * np.exp(-b*x)) + c\n",
    "\n",
    "#print(list(zip(x,y)))\n",
    "plt.plot(x, y, '-r')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([x.min(), x.max()])\n",
    "axes.set_ylim([y.min(), y.max()])\n",
    "\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Bonus')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "while False: #set this to True to see your bonus points based on your hypothetical percentile\n",
    "    try:\n",
    "        x_in=float(input('percentile:'))\n",
    "        bonus_out=np.round((a * np.exp(-b*x_in)) + c)\n",
    "        print('At {:0.0f} percentile, you will get {:0.1f} bonus points'.format(x_in,bonus_out))\n",
    "    except:\n",
    "        print(\"Exiting\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here. Feel free to make as many cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
